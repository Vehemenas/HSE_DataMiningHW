{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №3 (ИАД-16)\n",
    "## Линейная регрессия: переобучение и регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы на примерах увидим, как переобучаются линейные модели, разберем, почему так происходит, и выясним, как диагностировать и контролировать переобучение.\n",
    "\n",
    "Во всех ячейках, где написан комментарий с инструкциями, нужно написать код, выполняющий эти инструкции. Остальные ячейки с кодом (без комментариев) нужно просто выполнить. Кроме того, в задании требуется отвечать на вопросы; ответы нужно вписывать после выделенного слова \"__Ответ:__\".\n",
    "\n",
    "Напоминаем, что посмотреть справку любого метода или функции (узнать, какие у нее аргументы и что она делает) можно с помощью комбинации Shift+Tab. Нажатие Tab после имени объекта и точки позволяет посмотреть, какие методы и переменные есть у этого объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем работать с датасетом __\"bikes_rent.csv\"__, в котором по дням записаны календарная информация и погодные условия, характеризующие автоматизированные пункты проката велосипедов, а также число прокатов в этот день. Последнее мы будем предсказывать; таким образом, мы будем решать задачу регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знакомство с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите датасет с помощью функции __pandas.read_csv__ в переменную __df__. Выведите первые 5 строчек, чтобы убедиться в корректном считывании данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (0 баллов)\n",
    "# Считайте данные и выведите первые 5 строк\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого дня проката известны следующие признаки:\n",
    "* _season_: 1 - весна, 2 - лето, 3 - осень, 4 - зима\n",
    "* _yr_: 0 - 2011, 1 - 2012\n",
    "* _mnth_: от 1 до 12 (соответственно январь---декабрь)\n",
    "* _holiday_: 0 - нет праздника, 1 - есть праздник\n",
    "* _weekday_: от 0 до 6 (соответственно понедельник---воскресенье)\n",
    "* _workingday_: 0 - нерабочий день, 1 - рабочий день\n",
    "* _workthersit_: оценка благоприятности погоды от 1 (чистый, ясный день) до 4 (ливень, туман)\n",
    "* _temp_: температура в Цельсиях\n",
    "* _atemp_: температура по ощущениям в Цельсиях\n",
    "* _hum_: влажность\n",
    "* _windspeed(mph)_: скорость ветра в милях в час\n",
    "* _windspeed(ms)_: скорость ветра в метрах в секунду\n",
    "* _cnt_: количество арендованных велосипедов (это целевой признак, его мы будем предсказывать)\n",
    "\n",
    "Итак, у нас есть вещественные, бинарные и номинальные (порядковые) признаки, и со всеми из них можно работать как с вещественными. Давайте посмотрим на графиках, как целевой признак зависит от остальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3bd3ec658c5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cnt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"scatter\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA28AAAJPCAYAAADrFOx+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRuI85FUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ef53cae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(15, 10))\n",
    "for idx, feature in enumerate(df.columns[:-1]):\n",
    "    df.plot(feature, \"cnt\", subplots=True, kind=\"scatter\", ax=axes[idx / 4, idx % 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Блок 1. Ответьте на вопросы (каждый 0.25 балла):__\n",
    "1. Каков характер зависимости числа прокатов от месяца? \n",
    "   * ответ:\n",
    "1. В какие дни: рабочие или выходные, людям чаще нужен велосипед?\n",
    "   * ответ: \n",
    "1. Укажите одну переменную, которая не влияет на cnt.\n",
    "   * ответ:\n",
    "1. Укажите один или два признака, от которых число прокатов скорее всего зависит линейно\n",
    "   * ответ: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте более строго оценим уровень линейной зависимости между признаками и целевой переменной. Хорошей мерой линейной зависимости между двумя векторами является корреляция Пирсона. В pandas ее можно посчитать с помощью двух методов датафрейма: corr и corrwith. Метод df.corr вычисляет матрицу корреляций всех признаков из датафрейма. Методу df.corrwith нужно подать еще один датафрейм в качестве аргумента, и тогда он посчитает попарные корреляции между признаками из df и этого датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Код 1.1 (0.5 балла)\n",
    "# Посчитайте корреляции всех признаков, кроме последнего, с последним с помощью метода corrwith:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В выборке есть признаки, коррелирующие с целевым, а значит, задачу можно решать линейными методами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По графикам видно, что некоторые признаки похожи друг на друга. Поэтому давайте также посчитаем корреляции между вещественными признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Код 1.2 (0.5 балла)\n",
    "# Посчитайте попарные корреляции между признаками temp, atemp, hum, windspeed(mph), windspeed(ms) и cnt\n",
    "# с помощью метода corr:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На диагоналях, как и полагается, стоят единицы. Однако в матрице имеются еще две пары сильно коррелирующих столбцов: temp и atemp (коррелируют по своей природе) и два windspeed (потому что это просто перевод одних единиц в другие). Далее мы увидим, что этот факт негативно сказывается на обучении линейной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоследок посмотрим средние признаков (метод mean), чтобы оценить масштаб признаков и доли единиц у бинарных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Код 1.3 (0.5 балла)\n",
    "# Выведите средние признаков\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки имеют разный масштаб, значит для дальнейшей работы нам лучше нормировать матрицу объекты-признаки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем обучить самую простую линейную регрессию\n",
    "А именно, построим зависимость cnt от atemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Код 1.4 (1 балл)\n",
    "# Создайте объект линейного регрессора, обучите его на X = df[\"atemp\"] и y = df[\"cnt]\n",
    "# Затем сделайте предсказание на X_test = linspace (переменная, объявленная ниже) и запишите в переменную y_test\n",
    "linspace = np.linspace(0, 40, 1000)[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e80192466cfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"atemp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cnt\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(df[\"atemp\"], df[\"cnt\"])\n",
    "plt.plot(linspace.ravel(), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должна получиться прямая, проходящая через изображенные точки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проблема первая: коллинеарные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, в наших данных один признак дублирует другой, и есть еще два очень похожих. Конечно, мы могли бы сразу удалить дубликаты, но давайте посмотрим, как бы происходило обучение модели, если бы мы не заметили эту проблему. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала проведем масштабирование, или стандартизацию признаков: из каждого признака вычтем его среднее и поделим на дисперсию. Это можно сделать с помощью метода scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2899e6a05183>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cnt\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "X = scale(df[df.columns[:-1]])\n",
    "y = df[\"cnt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обучим линейную регрессию на полных данных и посмотрим на веса признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Код 2.1 (1 балл)\n",
    "# Создайте объект линейного регрессора, обучите его на всех данных и выведите веса модели \n",
    "# (веса хранятся в переменной coef_ класса регрессора).\n",
    "# Можно выводить пары (название признака, вес), воспользовавшись функцией zip, встроенной в язык python\n",
    "# Названия признаков хранятся в переменной df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что веса при линейно-зависимых признаках по модулю значительно больше, чем при других признаках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы понять, почему так произошло, вспомним аналитическую формулу, по которой вычисляются веса линейной модели в методе наименьших квадратов:\n",
    "\n",
    "$w = (X^TX)^{-1} X^T y$.\n",
    "\n",
    "Если в X есть коллинеарные (линейно-зависимые) столбцы, матрица $X^TX$ становится вырожденной, и формула перестает быть корректной. Чем более зависимы признаки, тем меньше определитель этой матрицы и тем хуже аппроксимация $Xw \\approx y$. Такая ситуацию называют _проблемой мультиколлинеарности_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С парой temp-atemp чуть менее коррелирующих переменных такого не произошло, однако на практике всегда стоит внимательно следить за коэффициентами при похожих признаках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Решение__ проблемы мультиколлинеарности состоит в _регуляризации_ линейной модели. К оптимизируемому функционалу $||Xw-y||$ прибавляют L1 или L2 норму весов, умноженную на коэффициент регуляризации $\\alpha$. В первом случае метод называется Lasso, а во втором — Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите регрессоры Ridge и Lasso с параметрами по умолчанию и убедитесь, что проблема с весами решилась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Код 2.2 (0.5 балла)\n",
    "# Обучите линейную модель с L1-регуляризацией\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Код 2.3 (0.5 балла)\n",
    "# Обучите линейную модель с L2-регуляризацией\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Блок 2. Поясните,__ каким образом введение регуляризации решает проблему с весами и мультиколлинеарностью.\n",
    "\n",
    "__Ваш ответ (1 балл)__: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проблема вторая: неинформативные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от L2-регуляризации, L1 обнуляет веса при некоторых признаках. Объяснение последнему факту было дано на лекции (всё из-за ромбообразных линий уровня L1-нормы).\n",
    "\n",
    "Давайте пронаблюдаем, как меняются веса при увеличении коэффициента регуляризации $\\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-38f8c21fe0c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Код 3.1 (1 балл)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0malphas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcoefs_lasso\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# матрица весов размера (число регрессоров) x (число признаков)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcoefs_ridge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Для каждого значения коэффициента из alphas обучите регрессор Lasso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Код 3.1 (1 балл)\n",
    "alphas = np.arange(1, 500, 50)\n",
    "coefs_lasso = np.zeros((alphas.shape[0], X.shape[1])) # матрица весов размера (число регрессоров) x (число признаков)\n",
    "coefs_ridge = np.zeros((alphas.shape[0], X.shape[1]))\n",
    "# Для каждого значения коэффициента из alphas обучите регрессор Lasso\n",
    "# и запишите веса в соответствующую строку матрицы coefs_lasso,\n",
    "# а затем обучите Ridge и запишите веса в coefs_ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем динамику весов при увеличении параметра регуляризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for coef, feature in zip(coefs_lasso.T, df.columns):\n",
    "    plt.plot(alphas, coef, label=feature, color=np.random.rand(3))\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.4, 0.95))\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"feature weight\")\n",
    "plt.title(\"Lasso\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for coef, feature in zip(coefs_ridge.T, df.columns):\n",
    "    plt.plot(alphas, coef, label=feature, color=np.random.rand(3))\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.4, 0.95))\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"feature weight\")\n",
    "plt.title(\"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Блок 3. Ответьте на вопросы (каждый 0.25 балла)__:\n",
    "1. Какой регрессор (Ridge или Lasso) агрессивнее уменьшает веса?\n",
    "    * Ответ:\n",
    "1. Что произойдет с весами Lasso, если alpha сделать очень большим? Поясните, почему так происходит.\n",
    "    * Ответ: \n",
    "1. Можно ли утверждать, что Lasso исключает один из признаков windspeed при любом значении alpha? А Ridge?\n",
    "    * Ответ:   \n",
    "1. Какой из регрессоров подойдет для отбора неинформативных признаков?\n",
    "    * Ответ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее будем работать с Lasso.\n",
    "\n",
    "Итак, мы видим, что при изменении alpha модель по-разному подбирает коэффициенты признаков. Нам нужно выбрать наилучшее alpha. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого, во-первых, нам нужна метрика качества. Будем использовать в качестве метрики сам оптимизируемый функционал метода наименьших квадратов, то есть Mean Square Error.\n",
    "\n",
    "Во-вторых, нужно понять, на каких данных эту метрику считать. Нельзя выбирать alpha по значению MSE на обучающей выборке, потому что тогда мы не сможем оценить, как модель будет делать предсказания на новых для нее данных. Если мы выберем одно разбиение выборки на обучающую и тестовую (это называется holdout), то настроимся на конкретные \"новые\" данные, и вновь можем переобучиться. Поэтому будем делать несколько разбиений выборки, на каждом пробовать разные значения alpha, а затем усреднять MSE. Удобнее всего делать такие разбиения кросс-валидацией, то есть разделить выборку на K частей, или блоков, и каждый раз брать одну из них как тестовую, а из оставшихся блоков составлять обучающую выборку. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делать кросс-валидацию для регрессии в sklearn совсем просто: для этого в scikit-learn есть специальный класс __LassoCV__, который берет на вход список из alpha и для каждого из них вычисляет MSE на кросс-валидации. После обучения (если оставить параметр cv=3 по умолчанию) регрессор будет содержать переменную __mse\\_path\\___, матрицу размера len(alpha) × k, k = 3 (число блоков в кросс-валидации), содержащую значения MSE на тесте для соответствующих запусков. Кроме того, в переменной alpha\\_ будет храниться выбранное значение параметра регуляризации, а в coef\\_, традиционно, обученные веса, соответствующие этому alpha_.\n",
    "\n",
    "Обратите внимание, что регрессор может менять порядок, в котором он проходит по alphas; для сопоставления с матрицей MSE лучше использовать переменную регрессора alphas_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Код 3.2 (1 балл)\n",
    "# Обучите регрессор LassoCV на всех параметрах регуляризации из alpha\n",
    "# Постройте график _усредненного_ по строкам MSE в зависимости от alpha. \n",
    "# Выведите выбранное alpha, а также пары \"признак-коэффициент\" для обученного вектора коэффициентов\n",
    "alphas = np.arange(1, 100, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы выбрали некоторый параметр регуляризации. Давайте посмотрим, какие бы мы выбирали alpha, если бы делили выборку только один раз на обучающую и тестовую, то есть рассмотрим траектории MSE, соответствующие отдельным блокам выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Код 3.3 (1 балл)\n",
    "# Выведите значения alpha, соответствующие минимумам MSE на каждом разбиении (то есть по столбцам).\n",
    "# На трех отдельных графиках визуализируйте столбцы .mse_path_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На каждом разбиении оптимальное значение alpha свое, и ему соответствует большое MSE на других разбиениях. Получается, что мы настраиваемся на конкретные обучающие и контрольные выборки. При выборе alpha на кросс-валидации мы выбираем нечто \"среднее\", что будет давать приемлемое значение метрики на разных разбиениях выборки. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, как принято в анализе данных, давайте проинтерпретируем результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Блок 4. Ответьте на вопросы (каждый 0.5 балла):__\n",
    "1. В последней обученной модели выберите 4 признака с наибольшими (положительными) коэфициентами, посмотрите на визуализации зависимостей cnt от этих признаков, которые мы рисовали в блоке \"Знакомство с данными\". Видна ли возрастающая линейная зависимость cnt от этих признаков по графикам? Логично ли утверждать (из здравого смысла), что чем больше значение этих признаков, тем больше людей захотят взять велосипеды? \n",
    "    * Ответ:\n",
    "1. Выберите 3 признака с наибольшими по модулю отрицательными коэффициентами, посмотрите на соответствующие визуализации. Видна ли убывающая линейная зависимость? Логично ли утверждать, что чем больше величина этих признаков, тем меньше людей захотят взять велосипеды?\n",
    "    * Ответ:\n",
    "1. Выберите признаки с нулевыми коэффициентами. Как вы думаете, почему модель исключила их из модели (вновь посмотрите на графики)? Верно ли, что они никак не влияют на спрос на велосипеды?\n",
    "    * Ответ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы посмотрели, как можно следить за адекватностью линейной модели, как отбирать признаки и как грамотно, по возможности не настраиваясь на какую-то конкретную порцию данных, подбирать коэффициент регуляризации. \n",
    "\n",
    "Стоит отметить, что с помощью кросс-валидации удобно подбирать лишь небольшое число параметров (1, 2, максимум 3), потому что для каждой допустимой их комбинации нам приходится несколько раз обучать модель, а это времязатратный процесс, особенно если нужно обучаться на больших объемах данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

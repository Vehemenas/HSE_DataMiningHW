{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_data = pd.read_csv('data/train_data.csv')\n",
    "X_data_test = pd.read_csv('data/1234.csv', sep=';')\n",
    "X_data_ktest = pd.read_csv('data/test_data.csv')\n",
    "y_data = pd.read_csv('data/train_target.csv', header=-1, names=['agreed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_data_test = X_data_test['y']\n",
    "X_data_test.drop(['y'], axis = 1, inplace = True, errors = 'ignore')\n",
    "\n",
    "y_data_test = pd.DataFrame(y_data_test)\n",
    "y_data_test['y'] = y_data_test.apply(lambda row: 1 if row['y'] == 'yes' else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is everything ok?:  True\n",
      "And duplicates?:  False\n"
     ]
    }
   ],
   "source": [
    "print('Is everything ok?: ',  X_data.shape[0] == y_data.shape[0])\n",
    "print('And duplicates?: ',  np.all(X_data.duplicated() == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if balanced sample:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFfCAYAAAAS+IXqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c90de48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Checking if balanced sample:')\n",
    "y_data['agreed'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27595.000000</td>\n",
       "      <td>27595.000000</td>\n",
       "      <td>27595.000000</td>\n",
       "      <td>27595.000000</td>\n",
       "      <td>27595.000000</td>\n",
       "      <td>27595.000000</td>\n",
       "      <td>27595.000000</td>\n",
       "      <td>27595.000000</td>\n",
       "      <td>27595.000000</td>\n",
       "      <td>27595.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.085994</td>\n",
       "      <td>258.874542</td>\n",
       "      <td>2.568328</td>\n",
       "      <td>962.693169</td>\n",
       "      <td>0.172024</td>\n",
       "      <td>0.087211</td>\n",
       "      <td>93.577443</td>\n",
       "      <td>-40.503026</td>\n",
       "      <td>3.628844</td>\n",
       "      <td>5167.31696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.480548</td>\n",
       "      <td>260.511236</td>\n",
       "      <td>2.765561</td>\n",
       "      <td>186.371948</td>\n",
       "      <td>0.492548</td>\n",
       "      <td>1.567343</td>\n",
       "      <td>0.578193</td>\n",
       "      <td>4.616641</td>\n",
       "      <td>1.730084</td>\n",
       "      <td>72.22960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>92.201000</td>\n",
       "      <td>-50.800000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>4963.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>93.075000</td>\n",
       "      <td>-42.700000</td>\n",
       "      <td>1.344000</td>\n",
       "      <td>5099.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>93.749000</td>\n",
       "      <td>-41.800000</td>\n",
       "      <td>4.857000</td>\n",
       "      <td>5191.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>93.994000</td>\n",
       "      <td>-36.400000</td>\n",
       "      <td>4.961000</td>\n",
       "      <td>5228.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>94.000000</td>\n",
       "      <td>4199.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>94.767000</td>\n",
       "      <td>-26.900000</td>\n",
       "      <td>5.045000</td>\n",
       "      <td>5228.10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age      duration      campaign         pdays      previous  \\\n",
       "count  27595.000000  27595.000000  27595.000000  27595.000000  27595.000000   \n",
       "mean      40.085994    258.874542      2.568328    962.693169      0.172024   \n",
       "std       10.480548    260.511236      2.765561    186.371948      0.492548   \n",
       "min       17.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "25%       32.000000    101.000000      1.000000    999.000000      0.000000   \n",
       "50%       38.000000    179.000000      2.000000    999.000000      0.000000   \n",
       "75%       47.000000    320.000000      3.000000    999.000000      0.000000   \n",
       "max       94.000000   4199.000000     43.000000    999.000000      7.000000   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m  nr.employed  \n",
       "count  27595.000000    27595.000000   27595.000000  27595.000000  27595.00000  \n",
       "mean       0.087211       93.577443     -40.503026      3.628844   5167.31696  \n",
       "std        1.567343        0.578193       4.616641      1.730084     72.22960  \n",
       "min       -3.400000       92.201000     -50.800000      0.634000   4963.60000  \n",
       "25%       -1.800000       93.075000     -42.700000      1.344000   5099.10000  \n",
       "50%        1.100000       93.749000     -41.800000      4.857000   5191.00000  \n",
       "75%        1.400000       93.994000     -36.400000      4.961000   5228.10000  \n",
       "max        1.400000       94.767000     -26.900000      5.045000   5228.10000  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_features(data):\n",
    "    conv_data = data.copy()\n",
    "    \n",
    "    conv_data['default'] = conv_data.apply(lambda row: 1 if row['default'] == 'yes' else 0, axis=1)\n",
    "    \n",
    "    conv_data['housing'] = conv_data.apply(lambda row: 1 if row['housing'] == 'yes' else 0, axis=1)\n",
    "    \n",
    "    conv_data['loan'] = conv_data.apply(lambda row: 1 if row['loan'] == 'yes' else 0, axis=1)\n",
    "    \n",
    "    # nominal values\n",
    "    nom_df = conv_data[['poutcome', 'month', 'contact', 'day_of_week', 'education', 'marital', 'job']]\n",
    "    conv_data = conv_data.drop(nom_df.columns, axis=1)\n",
    "    nom_df = pd.get_dummies(nom_df)\n",
    "    conv_data = pd.concat([conv_data, nom_df], axis = 1)\n",
    "    \n",
    "    # drop unused\n",
    "    conv_data = conv_data.drop(['previous'], axis = 1)\n",
    "    \n",
    "    return conv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_data = convert_features(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling major feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_cols = X_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler()\n",
    "X_data, y_data = rus.fit_sample(X_data, y_data['agreed'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_data = pd.DataFrame(X_data)\n",
    "X_data.columns = X_cols\n",
    "y_data = pd.DataFrame(y_data)\n",
    "y_data.columns = ['agreed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6228, 56)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And updating test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_data_test = convert_features(X_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data_ktest = convert_features(X_data_ktest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 34791\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data['agreed'].values, test_size=0.25, \n",
    "                 random_state = RANDOM_SEED, stratify=y_data['agreed'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_importance_print(n, importances, importances_names):\n",
    "    indexes = importances.argsort()[-n:][::-1]\n",
    "    for i, index in enumerate(indexes):\n",
    "        print ('#{} Important feature is -- {} with {:.2f} importance'.format(i + 1, importances_names[index], importances[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file='output.csv',\n",
    "                             target='Prediction', index_label=\"Id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(0, predicted_labels.shape[0]),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ModelTester():\n",
    "    def __init__(self, parameters, model, scoring='roc_auc', njobs=-1, cv=3):\n",
    "        self.cv = GridSearchCV(model, parameters, scoring = scoring, n_jobs = njobs, cv = cv, verbose = 1)\n",
    "    \n",
    "    def test_model(self):\n",
    "        self.cv.fit(X_train, y_train);\n",
    "        print('Best score cv: ', self.cv.best_score_)\n",
    "        print('Params: ', self.cv.best_params_)\n",
    "    \n",
    "        y_predicted = self.cv.predict(X_test)\n",
    "        print('Score on test sample:', roc_auc_score(y_test, y_predicted))\n",
    "    \n",
    "        y_predicted = self.cv.predict(X_data_test)\n",
    "        print('Score on full sample:', roc_auc_score(y_data_test['y'].values, y_predicted))\n",
    "        \n",
    "    def best_estimator(self):\n",
    "        return self.cv.best_estimator_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 168 candidates, totalling 504 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 504 out of 504 | elapsed:   14.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cv:  0.928138551232\n",
      "Params:  {'max_depth': 16, 'max_features': 'auto', 'criterion': 'gini', 'class_weight': 'balanced'}\n",
      "Score on test sample: 0.871565945398\n",
      "Score on full sample: 0.8960295365\n"
     ]
    }
   ],
   "source": [
    "param = {'criterion':['gini', 'entropy'], 'max_features':[1, 2, 3, 4, 5, 'log2', 'auto'],\n",
    "         'max_depth':[2, 4, 8, 16, 32, 64], 'class_weight':['balanced', None]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = RandomForestClassifier(random_state=RANDOM_SEED))\n",
    "mt.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cv:  0.927138287749\n",
      "Params:  {'C': 0.01, 'kernel': 'linear', 'decision_function_shape': 'ovo', 'class_weight': None}\n",
      "Score on test sample: 0.849716695652\n",
      "Score on full sample: 0.859553331849\n"
     ]
    }
   ],
   "source": [
    "param = {'C': np.linspace(0.01, 0.03, num=5), \n",
    "              'class_weight':['balanced', None], 'kernel':['linear'],\n",
    "              'decision_function_shape' : ['ovo', 'ovr', None]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = SVC(random_state=RANDOM_SEED))\n",
    "mt.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cv:  0.92950684953\n",
      "Params:  {'algorithm': 'SAMME.R', 'learning_rate': 0.3}\n",
      "Score on test sample: 0.873488190977\n",
      "Score on full sample: 0.873140848313\n"
     ]
    }
   ],
   "source": [
    "param = {'algorithm': ['SAMME.R', 'SAMME'], 'learning_rate': [0.1, 0.3, 0.6, 0.8, 1.0]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = AdaBoostClassifier(random_state=RANDOM_SEED))\n",
    "mt.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 56 candidates, totalling 168 fits\n",
      "Best score cv:  0.822738756095\n",
      "Params:  {'criterion': 'gini', 'splitter': 'best', 'random_state': 34791, 'presort': False, 'max_features': 'auto', 'class_weight': 'balanced'}\n",
      "Score on test sample: 0.820150413654\n",
      "Score on full sample: 0.864072094138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 168 out of 168 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "param = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'max_features':[1, 2, 3, 4, 5, 'log2', 'auto'], \n",
    "         'class_weight' : ['balanced'], 'random_state':[RANDOM_SEED], 'presort':[True, False]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = DecisionTreeClassifier(random_state=RANDOM_SEED))\n",
    "mt.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=-1)]: Done 432 out of 432 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cv:  0.930849240485\n",
      "Params:  {'weights': 'distance', 'n_neighbors': 50, 'algorithm': 'ball_tree', 'leaf_size': 20, 'p': 1}\n",
      "Score on test sample: 0.870915846894\n",
      "Score on full sample: 0.898673272843\n"
     ]
    }
   ],
   "source": [
    "param = {'n_neighbors': [30, 50, 70], 'weights': ['uniform', 'distance'], 'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "         'leaf_size' : [20, 30, 50], 'p':[1, 2]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = KNeighborsClassifier())\n",
    "mt.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 56 candidates, totalling 168 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 168 out of 168 | elapsed:   48.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cv:  0.938931700091\n",
      "Params:  {'min_samples_leaf': 3, 'max_features': 5, 'loss': 'deviance', 'presort': True, 'n_estimators': 300}\n",
      "Score on test sample: 0.881201923236\n",
      "Score on full sample: 0.891405657369\n"
     ]
    }
   ],
   "source": [
    "param = {'loss': ['deviance', 'exponential'], 'max_features':[1, 2, 3, 4, 5, 'log2', 'auto'], 'presort':[True, False],\n",
    "         'n_estimators':[200, 300], 'min_samples_leaf' : [3]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = GradientBoostingClassifier(random_state=RANDOM_SEED))\n",
    "mt.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 224 candidates, totalling 672 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 370 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 620 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 672 out of 672 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cv:  0.945777051993\n",
      "Params:  {'max_depth': 5, 'objective': 'rank:pairwise', 'n_estimators': 50}\n",
      "Score on test sample: 0.890196052549\n",
      "Score on full sample: 0.883327522993\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth': range(2, 10), 'n_estimators': [4, 5, 6, 25, 35, 50, 150], 'objective' : \n",
    "         ['reg:linear', 'binary:logistic', 'binary:logitraw', 'rank:pairwise']}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = XGBClassifier())\n",
    "mt.test_model()\n",
    "clf = mt.best_estimator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         'learning_rate':[0.01, 0.1], 'min_child_weight':[4,5,6],\n",
    "         'gamma':[i/10.0 for i in range(0,5)], 'colsample_bytree': [0.4, 0.6, 0.8, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

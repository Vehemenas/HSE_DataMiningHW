{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data analysis project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_In this project I am going to write a program to predict the number likes post is going to get in vk._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Выполнил__: Булгаков Дмитрий (ИАД16)\n",
    "\n",
    "__Дедлайн__: 23:59 10.04.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "VK library quiet installation and import into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install vk # makes it quiet\n",
    "import vk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Starting new vk session in order to parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vk_session = vk.Session() # starting new session\n",
    "vk_api = vk.API(vk_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Getting number of posts in selected vk group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts in selected group:  13964\n"
     ]
    }
   ],
   "source": [
    "selected_group = 'hse_overheard' # no other ideas :c\n",
    "posts_number = vk_api.wall.get(domain=selected_group)[0] # number of posts is stored in first element\n",
    "print('Number of posts in selected group: ', posts_number - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Writing a function to parse more, than 100 posts from group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all_posts(page, n_posts, api):\n",
    "    all_posts = api.wall.get(domain=page, count=n_posts)\n",
    "    n_loaded = len(all_posts)\n",
    "    while n_loaded < n_posts: # loop to load more, than 100 posts\n",
    "        s = api.wall.get(domain=page, offset=n_loaded, count=(n_posts - n_loaded)) # update offset\n",
    "        all_posts += s[1:] # no need for first element\n",
    "        n_loaded += len(s) - 1 # update n_loaded\n",
    "    return all_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading all posts from group for future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded posts:  1500\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    loaded_posts = load_all_posts(page=selected_group, n_posts=1501, api=vk_api)[1:] # no need for posts number element\n",
    "    # 1500 for this time, because I have small amount of ram avaliable :c\n",
    "    print('Number of loaded posts: ', len(loaded_posts))\n",
    "except: # timout errors are often to occur\n",
    "    print('Error occured! Try again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading required libs to preprocess data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install pymorphy2 -q # silent install again\n",
    "# !pip install stop_words -q # needed to remove stop words\n",
    "from stop_words import get_stop_words\n",
    "import pymorphy2 # need this one to convert words to normal time\n",
    "import datetime # needed to convert response date \n",
    "import string # needed to work with strings\n",
    "from nltk.tokenize import TweetTokenizer # needed to split text\n",
    "import pandas as pd # required to work with dataframes\n",
    "from ipywidgets import IntProgress # progressbar\n",
    "from IPython.display import display # progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Writing functions to process text data. Converting words to normal form and removing punctuation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(text) # spliting text into words\n",
    "\n",
    "def convert_to_normal_form(words_list):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    normal_forms_list = []\n",
    "    for word in words_list:\n",
    "        if word not in string.punctuation and word[0] != \"<\":\n",
    "            norm_form = morph.parse(word)[0].normal_form #getting normal form of a word\n",
    "            normal_forms_list.append(norm_form) #adding it to list\n",
    "    return normal_forms_list\n",
    "\n",
    "def convert_text(text):\n",
    "    words_list = split_text(text) # spliting text into words\n",
    "    norm_words_list = convert_to_normal_form(words_list) # words into normal form\n",
    "    filtered_words = [w for w in norm_words_list if not w in get_stop_words('russian')] # removing stop words\n",
    "    return \" \".join(filtered_words) # joining words to a sentence again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Writing a function to convert received list into another with another data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_posts(posts_list):\n",
    "    progress = IntProgress() \n",
    "    progress.max = len(posts_list) # initializing progressbar\n",
    "    progress.description = 'Processing data convertion'\n",
    "    display(progress)\n",
    "    \n",
    "    updated_posts = [] # list of new posts' list structure\n",
    "    for i, post in enumerate(posts_list): \n",
    "        tmp_dict = {} # creating empty dictionary for each post\n",
    "        tmp_dict['likes_number'] = int(post['likes']['count']) # getting likes count\n",
    "        tmp_dict['text'] = convert_text(post['text']) # converting text into normal form\n",
    "        tmp_dict['text_length'] = len(post['text']) # calculating text length\n",
    "        tmp_dict['post_hour'] = int(datetime.datetime.fromtimestamp(post['date']).strftime('%H')) # parsing only post hour\n",
    "        tmp_dict['post_month'] = int(datetime.datetime.fromtimestamp(post['date']).strftime('%m')) # and post month\n",
    "        tmp_dict['signed'] = int(post['from_id'] != -57354358) # checking whether post is signed or not\n",
    "        # checking if any attacment exists\n",
    "        tmp_dict['with_attachment'] = 1 if 'attachment' in post.keys() else 0\n",
    "        tmp_dict['pinned'] = 1 if 'is_pinned' in post.keys() else 0 # cheking if post is pinned\n",
    "        tmp_dict['repost'] = 1 if post['post_type'] == 'copy' else 0 # cheking if repost\n",
    "        updated_posts.append(tmp_dict)\n",
    "        progress.value += 1 # increasing progressbar value\n",
    "    progress.description = 'Done convertion!'\n",
    "    return updated_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Converting list of posts into new more convenient one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "converted_posts = convert_posts(loaded_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Creating object-feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframe from parsed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes_number</th>\n",
       "      <th>pinned</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>post_month</th>\n",
       "      <th>repost</th>\n",
       "      <th>signed</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>with_attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>выпуск заниматься студент прикладной математик...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>поступать юрфак набигай регион общага родитель...</td>\n",
       "      <td>426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>рассказать чувствовать узнать поступить хороши...</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>удивительно 30-40 оставаться чайлдфри убедить ...</td>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>научный интерес 30 существовать феминистка арб...</td>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   likes_number  pinned  post_hour  post_month  repost  signed  \\\n",
       "0             0       0         18           6       0       0   \n",
       "1             2       0         23           6       0       0   \n",
       "2             4       0         14           6       0       0   \n",
       "3            29       0          9           6       0       0   \n",
       "4             8       0         22           6       0       0   \n",
       "\n",
       "                                                text  text_length  \\\n",
       "0  выпуск заниматься студент прикладной математик...           67   \n",
       "1  поступать юрфак набигай регион общага родитель...          426   \n",
       "2  рассказать чувствовать узнать поступить хороши...          110   \n",
       "3  удивительно 30-40 оставаться чайлдфри убедить ...          407   \n",
       "4  научный интерес 30 существовать феминистка арб...          412   \n",
       "\n",
       "   with_attachment  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_frame = pd.DataFrame(converted_posts)\n",
    "posts_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And describing posts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes_number</th>\n",
       "      <th>pinned</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>post_month</th>\n",
       "      <th>repost</th>\n",
       "      <th>signed</th>\n",
       "      <th>text_length</th>\n",
       "      <th>with_attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.751333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.180000</td>\n",
       "      <td>3.732000</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.930667</td>\n",
       "      <td>0.223333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31.156197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.067191</td>\n",
       "      <td>1.664339</td>\n",
       "      <td>0.168795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>357.668800</td>\n",
       "      <td>0.416619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>474.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5035.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       likes_number  pinned    post_hour   post_month       repost  signed  \\\n",
       "count   1500.000000  1500.0  1500.000000  1500.000000  1500.000000  1500.0   \n",
       "mean      18.751333     0.0    15.180000     3.732000     0.029333     0.0   \n",
       "std       31.156197     0.0     6.067191     1.664339     0.168795     0.0   \n",
       "min        0.000000     0.0     0.000000     1.000000     0.000000     0.0   \n",
       "25%        2.000000     0.0    12.000000     2.000000     0.000000     0.0   \n",
       "50%        7.000000     0.0    16.000000     4.000000     0.000000     0.0   \n",
       "75%       23.000000     0.0    20.000000     5.000000     0.000000     0.0   \n",
       "max      474.000000     0.0    23.000000     6.000000     1.000000     0.0   \n",
       "\n",
       "       text_length  with_attachment  \n",
       "count  1500.000000      1500.000000  \n",
       "mean    239.930667         0.223333  \n",
       "std     357.668800         0.416619  \n",
       "min       0.000000         0.000000  \n",
       "25%      67.000000         0.000000  \n",
       "50%     134.000000         0.000000  \n",
       "75%     275.250000         0.000000  \n",
       "max    5035.000000         1.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Creating object-feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer # loading count vectorizer\n",
    "\n",
    "cv = TfidfVectorizer(norm='l1', max_features = 1000, analyzer = 'word', strip_accents='unicode', binary=True)\n",
    "train_features = cv.fit_transform(posts_frame['text']).toarray() # vectorizing texts\n",
    "train_frame = posts_frame.join(pd.DataFrame(train_features, columns=cv.get_feature_names())) # transfering it to pandas\n",
    "\n",
    "train_frame.drop(['likes_number','text'],inplace=True,axis=1,errors='ignore') # removing unnecessary columns\n",
    "value_frame = posts_frame['likes_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pinned</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>post_month</th>\n",
       "      <th>repost</th>\n",
       "      <th>signed</th>\n",
       "      <th>text_length</th>\n",
       "      <th>with_attachment</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>экономист</th>\n",
       "      <th>экономическии</th>\n",
       "      <th>электричка</th>\n",
       "      <th>юридическии</th>\n",
       "      <th>юрист</th>\n",
       "      <th>юрфак</th>\n",
       "      <th>являться</th>\n",
       "      <th>язык</th>\n",
       "      <th>якобы</th>\n",
       "      <th>ясин</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.180000</td>\n",
       "      <td>3.732000</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.930667</td>\n",
       "      <td>0.223333</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.067191</td>\n",
       "      <td>1.664339</td>\n",
       "      <td>0.168795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>357.668800</td>\n",
       "      <td>0.416619</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012615</td>\n",
       "      <td>0.018117</td>\n",
       "      <td>0.011144</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.013865</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.004234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5035.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129340</td>\n",
       "      <td>0.441839</td>\n",
       "      <td>0.091979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334288</td>\n",
       "      <td>0.504354</td>\n",
       "      <td>0.238118</td>\n",
       "      <td>0.213870</td>\n",
       "      <td>0.201969</td>\n",
       "      <td>0.103269</td>\n",
       "      <td>0.462557</td>\n",
       "      <td>0.236528</td>\n",
       "      <td>0.174195</td>\n",
       "      <td>0.097465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1007 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pinned    post_hour   post_month       repost  signed  text_length  \\\n",
       "count  1500.0  1500.000000  1500.000000  1500.000000  1500.0  1500.000000   \n",
       "mean      0.0    15.180000     3.732000     0.029333     0.0   239.930667   \n",
       "std       0.0     6.067191     1.664339     0.168795     0.0   357.668800   \n",
       "min       0.0     0.000000     1.000000     0.000000     0.0     0.000000   \n",
       "25%       0.0    12.000000     2.000000     0.000000     0.0    67.000000   \n",
       "50%       0.0    16.000000     4.000000     0.000000     0.0   134.000000   \n",
       "75%       0.0    20.000000     5.000000     0.000000     0.0   275.250000   \n",
       "max       0.0    23.000000     6.000000     1.000000     0.0  5035.000000   \n",
       "\n",
       "       with_attachment          000           10          100     ...       \\\n",
       "count      1500.000000  1500.000000  1500.000000  1500.000000     ...        \n",
       "mean          0.223333     0.000252     0.001951     0.000489     ...        \n",
       "std           0.416619     0.004742     0.019470     0.005204     ...        \n",
       "min           0.000000     0.000000     0.000000     0.000000     ...        \n",
       "25%           0.000000     0.000000     0.000000     0.000000     ...        \n",
       "50%           0.000000     0.000000     0.000000     0.000000     ...        \n",
       "75%           0.000000     0.000000     0.000000     0.000000     ...        \n",
       "max           1.000000     0.129340     0.441839     0.091979     ...        \n",
       "\n",
       "         экономист  экономическии   электричка  юридическии        юрист  \\\n",
       "count  1500.000000    1500.000000  1500.000000  1500.000000  1500.000000   \n",
       "mean      0.001051       0.001328     0.000691     0.000534     0.000542   \n",
       "std       0.012615       0.018117     0.011144     0.009194     0.007822   \n",
       "min       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.334288       0.504354     0.238118     0.213870     0.201969   \n",
       "\n",
       "             юрфак     являться         язык        якобы         ясин  \n",
       "count  1500.000000  1500.000000  1500.000000  1500.000000  1500.000000  \n",
       "mean      0.000291     0.000997     0.001482     0.000265     0.000243  \n",
       "std       0.004757     0.015235     0.013865     0.005270     0.004234  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       0.103269     0.462557     0.236528     0.174195     0.097465  \n",
       "\n",
       "[8 rows x 1007 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving train frame to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_frame.to_csv('traindata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Comparing different methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Splitting it into test and train samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_frame, value_frame, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare(est, param, est_name):\n",
    "    cv = GridSearchCV(est, param, n_jobs = -1)\n",
    "    cv.fit(X_train, y_train);\n",
    "    print('CV best score for', est_name, ': ', cv.best_score_)\n",
    "    \n",
    "    predicted = cv.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predicted)\n",
    "    print('MSE for', est_name, ':' , mse)\n",
    "    r2 = r2_score(y_test, predicted)\n",
    "    print('R^2 for', est_name, ':' , r2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best score for simple linear regression :  -92.6627023853\n",
      "MSE for simple linear regression : 389888.390702\n",
      "R^2 for simple linear regression : -420.516274215\n"
     ]
    }
   ],
   "source": [
    "parameters = {'fit_intercept':[True, False],'normalize':[True, False]}\n",
    "compare(LinearRegression(), parameters, 'simple linear regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Linear regression with L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best score for linear regression with L1 regularization :  0.224873824274\n",
      "MSE for linear regression with L1 regularization : 679.171584125\n",
      "R^2 for linear regression with L1 regularization : 0.26573377787\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha':np.arange(1, 100, 5), 'positive':[True, False],'normalize':[True, False], \n",
    "              'selection':['cyclic', 'random']}\n",
    "compare(Lasso(), parameters, 'linear regression with L1 regularization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Linear regression with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best score for linear regression with L2 regularization :  0.27902482471\n",
      "MSE for linear regression with L2 regularization : 666.251136282\n",
      "R^2 for linear regression with L2 regularization : 0.279702336991\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha':np.logspace(1.0, 10.0, 101.00), 'fit_intercept':[True, False],'normalize':[True, False],\n",
    "              'solver':['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'auto']}\n",
    "compare(Ridge(), parameters, 'linear regression with L2 regularization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Decision trees and random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best score for decision tree classifier :  0.174285714286\n",
      "MSE for decision tree classifier : 1215.97333333\n",
      "R^2 for decision tree classifier : -0.314613518214\n"
     ]
    }
   ],
   "source": [
    "parameters = {'presort':[True, False],'max_depth': np.arange(1, 20), 'class_weight':['balanced', None], 'splitter':['random', 'best'],\n",
    "             'max_features':['auto', 'sqrt', 'log2', None]}\n",
    "compare(tree.DecisionTreeClassifier(), parameters, 'decision tree classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000022788557780, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-35.pyc', '__doc__': None, '__file__': r'C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\b...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000022788557780, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-35.pyc', '__doc__': None, '__file__': r'C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\b...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-06-12T21:21:09.624392', 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'session': 'A53E01A4C04342AA84B2F304A859EF18', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'A53E01A4C04342AA84B2F304A859EF18']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-06-12T21:21:09.624392', 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'session': 'A53E01A4C04342AA84B2F304A859EF18', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'A53E01A4C04342AA84B2F304A859EF18'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-06-12T21:21:09.624392', 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'session': 'A53E01A4C04342AA84B2F304A859EF18', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method InteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\"\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-294-26b1cb07d3bb>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n   2830                 code = compiler(mod, cell_name, \"single\")\n-> 2831                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000022796E7EAE0, file \"<ipython-input-294-26b1cb07d3bb>\", line 3>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2832                     return True\n   2833 \n   2834             # Flush softspace\n   2835             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000022796E7EAE0, file \"<ipython-input-294-26b1cb07d3bb>\", line 3>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000022796E7EAE0, file \"<ipython-input-294-26b1cb07d3bb>\", line 3>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", '# !pip install vk # makes it quiet\\nimport vk', 'vk_session = vk.Session() # starting new session\\nvk_api = vk.API(vk_session)', \"selected_group = 'hse_overheard' # no other idea... of posts in selected group: ', posts_number - 1)\", 'def load_all_posts(page, n_posts, api):\\n    all_...len(s) - 1 # update n_loaded\\n    return all_posts', \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", '# !pip install pymorphy2 -q # silent install aga...from IPython.display import display # progressbar', 'def split_text(text):\\n    tokenizer = TweetToken...ltered_words) # joining words to a sentence again', \"def convert_posts(posts_list):\\n    progress = In...ion = 'Done convertion!'\\n    return updated_posts\", 'converted_posts = convert_posts(loaded_posts)', 'import pandas as pd', 'posts_frame = pd.DataFrame(converted_posts)\\nposts_frame.head()', 'posts_frame.describe()', \"from sklearn.feature_extraction.text import Coun...columns\\nvalue_frame = posts_frame['likes_number']\", 'train_frame.describe()', \"# train_frame.to_csv('traindata.csv')\", 'from sklearn.cross_validation import train_test_...ame, value_frame, test_size=0.3, random_state=42)', ...], 'IntProgress': <class 'ipywidgets.widgets.widget_int.IntProgress'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, 'Out': {14:    likes_number  pinned  post_hour  post_month  ...    0  \n3                0  \n4                0  , 15:        likes_number  pinned   post_hour  post_mo...  0.00000  \nmax     2270.00000          1.00000  , 17:        pinned   post_hour  post_month     repost...  1.000000    1.000000  \n\n[8 rows x 4031 columns], 25: 0.0068924852394986564, 27: 0.018093065218199256, 28: {'alpha': 1, 'normalize': False, 'positive': True, 'selection': 'cyclic'}, 30: -9962768471560722.0, 34: -9962768471560722.0, 39: dict_keys(['max_leaf_nodes', 'class_weight', 'pr...min_samples_split', 'random_state', 'criterion']), 40: 0.2742857142857143, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'Ridge': <class 'sklearn.linear_model.ridge.Ridge'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", '# !pip install vk # makes it quiet\\nimport vk', 'vk_session = vk.Session() # starting new session\\nvk_api = vk.API(vk_session)', \"selected_group = 'hse_overheard' # no other idea... of posts in selected group: ', posts_number - 1)\", 'def load_all_posts(page, n_posts, api):\\n    all_...len(s) - 1 # update n_loaded\\n    return all_posts', \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", '# !pip install pymorphy2 -q # silent install aga...from IPython.display import display # progressbar', 'def split_text(text):\\n    tokenizer = TweetToken...ltered_words) # joining words to a sentence again', \"def convert_posts(posts_list):\\n    progress = In...ion = 'Done convertion!'\\n    return updated_posts\", 'converted_posts = convert_posts(loaded_posts)', 'import pandas as pd', 'posts_frame = pd.DataFrame(converted_posts)\\nposts_frame.head()', 'posts_frame.describe()', \"from sklearn.feature_extraction.text import Coun...columns\\nvalue_frame = posts_frame['likes_number']\", 'train_frame.describe()', \"# train_frame.to_csv('traindata.csv')\", 'from sklearn.cross_validation import train_test_...ame, value_frame, test_size=0.3, random_state=42)', ...], 'IntProgress': <class 'ipywidgets.widgets.widget_int.IntProgress'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, 'Out': {14:    likes_number  pinned  post_hour  post_month  ...    0  \n3                0  \n4                0  , 15:        likes_number  pinned   post_hour  post_mo...  0.00000  \nmax     2270.00000          1.00000  , 17:        pinned   post_hour  post_month     repost...  1.000000    1.000000  \n\n[8 rows x 4031 columns], 25: 0.0068924852394986564, 27: 0.018093065218199256, 28: {'alpha': 1, 'normalize': False, 'positive': True, 'selection': 'cyclic'}, 30: -9962768471560722.0, 34: -9962768471560722.0, 39: dict_keys(['max_leaf_nodes', 'class_weight', 'pr...min_samples_split', 'random_state', 'criterion']), 40: 0.2742857142857143, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'Ridge': <class 'sklearn.linear_model.ridge.Ridge'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\bulga\\Dropbox\\Учеба\\ВШЭ\\Майнор\\HSE_DataMiningHW\\DataAnalysis\\Homeworks\\Solutions\\Project\\Part 2\\<ipython-input-294-26b1cb07d3bb> in <module>()\n      1 \n      2 \n----> 3 \n      4 parameters = {'n_estimators':[10, 20, 30], 'class_weight':['balanced', 'balanced_subsample', None],\n      5              'max_features':['auto', 'sqrt', 'log2', None]}\n      6 compare(RandomForestClassifier(), parameters, 'random forest classifier')\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\bulga\\Dropbox\\Учеба\\ВШЭ\\Майнор\\HSE_DataMiningHW\\DataAnalysis\\Homeworks\\Solutions\\Project\\Part 2\\<ipython-input-269-b41b5f451bc3> in compare(est=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), param={'class_weight': ['balanced', 'balanced_subsample', None], 'max_features': ['auto', 'sqrt', 'log2', None], 'n_estimators': [10, 20, 30]}, est_name='random forest classifier')\n      1 \n      2 \n----> 3 \n      4 def compare(est, param, est_name):\n      5     cv = GridSearchCV(est, param, n_jobs = -1)\n      6     cv.fit(X_train, y_train);\n      7     print('CV best score for', est_name, ': ', cv.best_score_)\n      8     \n      9     predicted = cv.predict(X_test)\n     10     mse = mean_squared_error(y_test, predicted)\n     11     print('MSE for', est_name, ':' , mse)\n     12     r2 = r2_score(y_test, predicted)\n     13     print('R^2 for', est_name, ':' , r2)    \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=      pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], y=485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64)\n    799         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    800             Target relative to X for classification or regression;\n    801             None for unsupervised learning.\n    802 \n    803         \"\"\"\n--> 804         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X =       pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns]\n        y = 485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64\n        self.param_grid = {'class_weight': ['balanced', 'balanced_subsample', None], 'max_features': ['auto', 'sqrt', 'log2', None], 'n_estimators': [10, 20, 30]}\n    805 \n    806 \n    807 class RandomizedSearchCV(BaseSearchCV):\n    808     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=      pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], y=485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    548         )(\n    549             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    550                                     train, test, self.verbose, parameters,\n    551                                     self.fit_params, return_parameters=True,\n    552                                     error_score=self.error_score)\n--> 553                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    554                 for train, test in cv)\n    555 \n    556         # Out is a list of triplet: score, estimator, n_test_samples\n    557         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 12 21:21:37 2016\nPID: 1632                 Python 3.5.1: C:\\Users\\bulga\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], 485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, <function _passthrough_scorer>, array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), 0, {'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], 485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, <function _passthrough_scorer>, array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), 0, {'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], y=485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, scorer=<function _passthrough_scorer>, train=array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), test=array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), verbose=0, parameters={'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1526 \n   1527     try:\n   1528         if y_train is None:\n   1529             estimator.fit(X_train, **fit_params)\n   1530         else:\n-> 1531             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None, verbose=0,\n            warm_start=False)>\n        X_train =       pinned  post_hour  post_month  repost  sig...000  \n1126  0.000000  \n\n[650 rows x 1007 columns]\n        y_train = 1387     73\n1478    150\n915      73\n638      16\n...  44\n1126     18\nName: likes_number, dtype: int64\n        fit_params = {}\n   1532 \n   1533     except Exception as e:\n   1534         if error_score == 'raise':\n   1535             raise\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), sample_weight=None)\n    285             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    286                              backend=\"threading\")(\n    287                 delayed(_parallel_build_trees)(\n    288                     t, self, X, y, sample_weight, i, len(trees),\n    289                     verbose=self.verbose, class_weight=self.class_weight)\n--> 290                 for i, t in enumerate(trees))\n        i = 9\n    291 \n    292             # Collect newly grown trees\n    293             self.estimators_.extend(trees)\n    294 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    795         self._smoothed_batch_duration = 0.0\n    796         try:\n    797             # Only set self._iterating to True if at least a batch\n    798             # was dispatched. In particular this covers the edge\n    799             # case of Parallel used with an exhausted iterator.\n--> 800             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    801                 self._iterating = True\n    802             else:\n    803                 self._iterating = False\n    804 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    653             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    654             if not tasks:\n    655                 # No more tasks available in the iterator: tell caller to stop.\n    656                 return False\n    657             else:\n--> 658                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    659                 return True\n    660 \n    661     def _print(self, msg, msg_args):\n    662         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    561         # If job.get() catches an exception, it closes the queue:\n    562         if self._aborting:\n    563             return\n    564 \n    565         if self._pool is None:\n--> 566             job = ImmediateComputeBatch(batch)\n        job = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    567             self._jobs.append(job)\n    568             self.n_dispatched_batches += 1\n    569             self.n_dispatched_tasks += len(batch)\n    570             self.n_completed_tasks += len(batch)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __init__(self=<sklearn.externals.joblib.parallel.ImmediateComputeBatch object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    175 \n    176     \"\"\"\n    177     def __init__(self, batch):\n    178         # Don't delay the application, to avoid keeping the input\n    179         # arguments in memory\n--> 180         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    181 \n    182     def get(self):\n    183         return self.results\n    184 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), None, 0, 10), {'class_weight': 'balanced_subsample', 'verbose': 0})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), None, 0, 10)\n        kwargs = {'class_weight': 'balanced_subsample', 'verbose': 0}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight='balanced_subsample')\n    109         if class_weight == 'subsample':\n    110             with warnings.catch_warnings():\n    111                 warnings.simplefilter('ignore', DeprecationWarning)\n    112                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    113         elif class_weight == 'balanced_subsample':\n--> 114             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n        curr_sample_weight = array([ 0.,  1.,  1.,  1.,  0.,  0.,  2.,  3.,  ...1.,  1.,  3.,  1.,  0.,  2.,  0.,  2.,  3.,  0.])\n        y = array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]])\n        indices = array([286,  41, 345, 507, 409, 232, 108,   2, 3...26, 453, 648, 290, 195, 523, 562, 453, 551, 103])\n    115 \n    116         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n    117     else:\n    118         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py in compute_sample_weight(class_weight='balanced', y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), indices=array([286,  41, 345, 507, 409, 232, 108,   2, 3...26, 453, 648, 290, 195, 523, 562, 453, 551, 103]))\n    157             weight_k = np.choose(np.searchsorted(classes_subsample,\n    158                                                  classes_full),\n    159                                  compute_class_weight(class_weight_k,\n    160                                                       classes_subsample,\n    161                                                       y_subsample),\n--> 162                                  mode='clip')\n    163 \n    164             classes_missing = set(classes_full) - set(classes_subsample)\n    165         else:\n    166             weight_k = compute_class_weight(class_weight_k,\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in choose(a=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...    62, 62, 63, 64, 65, 66, 67, 68], dtype=int64), choices=array([ 0.08722491,  0.17444981,  0.21907651,  0...42028986,  9.42028986,  9.42028986,  9.42028986]), out=None, mode='clip')\n    346     \"\"\"\n    347     try:\n    348         choose = a.choose\n    349     except AttributeError:\n    350         return _wrapit(a, 'choose', choices, out=out, mode=mode)\n--> 351     return choose(choices, out=out, mode=mode)\n        choose = <built-in method choose of numpy.ndarray object>\n        choices = array([ 0.08722491,  0.17444981,  0.21907651,  0...42028986,  9.42028986,  9.42028986,  9.42028986])\n        out = None\n        mode = 'clip'\n    352 \n    353 \n    354 def repeat(a, repeats, axis=None):\n    355     \"\"\"\n\nValueError: Need between 2 and (32) array objects (inclusive).\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 130, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 72, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 72, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\", line 1531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 290, in fit\n    for i, t in enumerate(trees))\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 800, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 658, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 566, in _dispatch\n    job = ImmediateComputeBatch(batch)\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 180, in __init__\n    self.results = batch()\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 72, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 72, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 114, in _parallel_build_trees\n    curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py\", line 162, in compute_sample_weight\n    mode='clip')\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 351, in choose\n    return choose(choices, out=out, mode=mode)\nValueError: Need between 2 and (32) array objects (inclusive).\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 140, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Jun 12 21:21:37 2016\nPID: 1632                 Python 3.5.1: C:\\Users\\bulga\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], 485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, <function _passthrough_scorer>, array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), 0, {'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], 485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, <function _passthrough_scorer>, array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), 0, {'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], y=485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, scorer=<function _passthrough_scorer>, train=array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), test=array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), verbose=0, parameters={'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1526 \n   1527     try:\n   1528         if y_train is None:\n   1529             estimator.fit(X_train, **fit_params)\n   1530         else:\n-> 1531             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None, verbose=0,\n            warm_start=False)>\n        X_train =       pinned  post_hour  post_month  repost  sig...000  \n1126  0.000000  \n\n[650 rows x 1007 columns]\n        y_train = 1387     73\n1478    150\n915      73\n638      16\n...  44\n1126     18\nName: likes_number, dtype: int64\n        fit_params = {}\n   1532 \n   1533     except Exception as e:\n   1534         if error_score == 'raise':\n   1535             raise\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), sample_weight=None)\n    285             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    286                              backend=\"threading\")(\n    287                 delayed(_parallel_build_trees)(\n    288                     t, self, X, y, sample_weight, i, len(trees),\n    289                     verbose=self.verbose, class_weight=self.class_weight)\n--> 290                 for i, t in enumerate(trees))\n        i = 9\n    291 \n    292             # Collect newly grown trees\n    293             self.estimators_.extend(trees)\n    294 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    795         self._smoothed_batch_duration = 0.0\n    796         try:\n    797             # Only set self._iterating to True if at least a batch\n    798             # was dispatched. In particular this covers the edge\n    799             # case of Parallel used with an exhausted iterator.\n--> 800             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    801                 self._iterating = True\n    802             else:\n    803                 self._iterating = False\n    804 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    653             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    654             if not tasks:\n    655                 # No more tasks available in the iterator: tell caller to stop.\n    656                 return False\n    657             else:\n--> 658                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    659                 return True\n    660 \n    661     def _print(self, msg, msg_args):\n    662         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    561         # If job.get() catches an exception, it closes the queue:\n    562         if self._aborting:\n    563             return\n    564 \n    565         if self._pool is None:\n--> 566             job = ImmediateComputeBatch(batch)\n        job = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    567             self._jobs.append(job)\n    568             self.n_dispatched_batches += 1\n    569             self.n_dispatched_tasks += len(batch)\n    570             self.n_completed_tasks += len(batch)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __init__(self=<sklearn.externals.joblib.parallel.ImmediateComputeBatch object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    175 \n    176     \"\"\"\n    177     def __init__(self, batch):\n    178         # Don't delay the application, to avoid keeping the input\n    179         # arguments in memory\n--> 180         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    181 \n    182     def get(self):\n    183         return self.results\n    184 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), None, 0, 10), {'class_weight': 'balanced_subsample', 'verbose': 0})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), None, 0, 10)\n        kwargs = {'class_weight': 'balanced_subsample', 'verbose': 0}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight='balanced_subsample')\n    109         if class_weight == 'subsample':\n    110             with warnings.catch_warnings():\n    111                 warnings.simplefilter('ignore', DeprecationWarning)\n    112                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    113         elif class_weight == 'balanced_subsample':\n--> 114             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n        curr_sample_weight = array([ 0.,  1.,  1.,  1.,  0.,  0.,  2.,  3.,  ...1.,  1.,  3.,  1.,  0.,  2.,  0.,  2.,  3.,  0.])\n        y = array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]])\n        indices = array([286,  41, 345, 507, 409, 232, 108,   2, 3...26, 453, 648, 290, 195, 523, 562, 453, 551, 103])\n    115 \n    116         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n    117     else:\n    118         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py in compute_sample_weight(class_weight='balanced', y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), indices=array([286,  41, 345, 507, 409, 232, 108,   2, 3...26, 453, 648, 290, 195, 523, 562, 453, 551, 103]))\n    157             weight_k = np.choose(np.searchsorted(classes_subsample,\n    158                                                  classes_full),\n    159                                  compute_class_weight(class_weight_k,\n    160                                                       classes_subsample,\n    161                                                       y_subsample),\n--> 162                                  mode='clip')\n    163 \n    164             classes_missing = set(classes_full) - set(classes_subsample)\n    165         else:\n    166             weight_k = compute_class_weight(class_weight_k,\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in choose(a=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...    62, 62, 63, 64, 65, 66, 67, 68], dtype=int64), choices=array([ 0.08722491,  0.17444981,  0.21907651,  0...42028986,  9.42028986,  9.42028986,  9.42028986]), out=None, mode='clip')\n    346     \"\"\"\n    347     try:\n    348         choose = a.choose\n    349     except AttributeError:\n    350         return _wrapit(a, 'choose', choices, out=out, mode=mode)\n--> 351     return choose(choices, out=out, mode=mode)\n        choose = <built-in method choose of numpy.ndarray object>\n        choices = array([ 0.08722491,  0.17444981,  0.21907651,  0...42028986,  9.42028986,  9.42028986,  9.42028986])\n        out = None\n        mode = 'clip'\n    352 \n    353 \n    354 def repeat(a, repeats, axis=None):\n    355     \"\"\"\n\nValueError: Need between 2 and (32) array objects (inclusive).\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bulga\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Jun 12 21:21:37 2016\nPID: 1632                 Python 3.5.1: C:\\Users\\bulga\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], 485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, <function _passthrough_scorer>, array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), 0, {'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], 485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, <function _passthrough_scorer>, array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), 0, {'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], y=485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, scorer=<function _passthrough_scorer>, train=array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), test=array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), verbose=0, parameters={'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1526 \n   1527     try:\n   1528         if y_train is None:\n   1529             estimator.fit(X_train, **fit_params)\n   1530         else:\n-> 1531             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None, verbose=0,\n            warm_start=False)>\n        X_train =       pinned  post_hour  post_month  repost  sig...000  \n1126  0.000000  \n\n[650 rows x 1007 columns]\n        y_train = 1387     73\n1478    150\n915      73\n638      16\n...  44\n1126     18\nName: likes_number, dtype: int64\n        fit_params = {}\n   1532 \n   1533     except Exception as e:\n   1534         if error_score == 'raise':\n   1535             raise\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), sample_weight=None)\n    285             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    286                              backend=\"threading\")(\n    287                 delayed(_parallel_build_trees)(\n    288                     t, self, X, y, sample_weight, i, len(trees),\n    289                     verbose=self.verbose, class_weight=self.class_weight)\n--> 290                 for i, t in enumerate(trees))\n        i = 9\n    291 \n    292             # Collect newly grown trees\n    293             self.estimators_.extend(trees)\n    294 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    795         self._smoothed_batch_duration = 0.0\n    796         try:\n    797             # Only set self._iterating to True if at least a batch\n    798             # was dispatched. In particular this covers the edge\n    799             # case of Parallel used with an exhausted iterator.\n--> 800             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    801                 self._iterating = True\n    802             else:\n    803                 self._iterating = False\n    804 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    653             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    654             if not tasks:\n    655                 # No more tasks available in the iterator: tell caller to stop.\n    656                 return False\n    657             else:\n--> 658                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    659                 return True\n    660 \n    661     def _print(self, msg, msg_args):\n    662         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    561         # If job.get() catches an exception, it closes the queue:\n    562         if self._aborting:\n    563             return\n    564 \n    565         if self._pool is None:\n--> 566             job = ImmediateComputeBatch(batch)\n        job = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    567             self._jobs.append(job)\n    568             self.n_dispatched_batches += 1\n    569             self.n_dispatched_tasks += len(batch)\n    570             self.n_completed_tasks += len(batch)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __init__(self=<sklearn.externals.joblib.parallel.ImmediateComputeBatch object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    175 \n    176     \"\"\"\n    177     def __init__(self, batch):\n    178         # Don't delay the application, to avoid keeping the input\n    179         # arguments in memory\n--> 180         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    181 \n    182     def get(self):\n    183         return self.results\n    184 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), None, 0, 10), {'class_weight': 'balanced_subsample', 'verbose': 0})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), None, 0, 10)\n        kwargs = {'class_weight': 'balanced_subsample', 'verbose': 0}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight='balanced_subsample')\n    109         if class_weight == 'subsample':\n    110             with warnings.catch_warnings():\n    111                 warnings.simplefilter('ignore', DeprecationWarning)\n    112                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    113         elif class_weight == 'balanced_subsample':\n--> 114             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n        curr_sample_weight = array([ 0.,  1.,  1.,  1.,  0.,  0.,  2.,  3.,  ...1.,  1.,  3.,  1.,  0.,  2.,  0.,  2.,  3.,  0.])\n        y = array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]])\n        indices = array([286,  41, 345, 507, 409, 232, 108,   2, 3...26, 453, 648, 290, 195, 523, 562, 453, 551, 103])\n    115 \n    116         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n    117     else:\n    118         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py in compute_sample_weight(class_weight='balanced', y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), indices=array([286,  41, 345, 507, 409, 232, 108,   2, 3...26, 453, 648, 290, 195, 523, 562, 453, 551, 103]))\n    157             weight_k = np.choose(np.searchsorted(classes_subsample,\n    158                                                  classes_full),\n    159                                  compute_class_weight(class_weight_k,\n    160                                                       classes_subsample,\n    161                                                       y_subsample),\n--> 162                                  mode='clip')\n    163 \n    164             classes_missing = set(classes_full) - set(classes_subsample)\n    165         else:\n    166             weight_k = compute_class_weight(class_weight_k,\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in choose(a=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...    62, 62, 63, 64, 65, 66, 67, 68], dtype=int64), choices=array([ 0.08722491,  0.17444981,  0.21907651,  0...42028986,  9.42028986,  9.42028986,  9.42028986]), out=None, mode='clip')\n    346     \"\"\"\n    347     try:\n    348         choose = a.choose\n    349     except AttributeError:\n    350         return _wrapit(a, 'choose', choices, out=out, mode=mode)\n--> 351     return choose(choices, out=out, mode=mode)\n        choose = <built-in method choose of numpy.ndarray object>\n        choices = array([ 0.08722491,  0.17444981,  0.21907651,  0...42028986,  9.42028986,  9.42028986,  9.42028986])\n        out = None\n        mode = 'clip'\n    352 \n    353 \n    354 def repeat(a, repeats, axis=None):\n    355     \"\"\"\n\nValueError: Need between 2 and (32) array objects (inclusive).\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-294-26b1cb07d3bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m parameters = {'n_estimators':[10, 20, 30], 'class_weight':['balanced', 'balanced_subsample', None],\n\u001b[0;32m      2\u001b[0m              'max_features':['auto', 'sqrt', 'log2', None]}\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcompare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'random forest classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-269-b41b5f451bc3>\u001b[0m in \u001b[0;36mcompare\u001b[1;34m(est, param, est_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CV best score for'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \"\"\"\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 for train, test in cv)\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000022788557780, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-35.pyc', '__doc__': None, '__file__': r'C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\b...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000022788557780, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-35.pyc', '__doc__': None, '__file__': r'C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\b...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-06-12T21:21:09.624392', 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'session': 'A53E01A4C04342AA84B2F304A859EF18', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'A53E01A4C04342AA84B2F304A859EF18']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-06-12T21:21:09.624392', 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'session': 'A53E01A4C04342AA84B2F304A859EF18', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'A53E01A4C04342AA84B2F304A859EF18'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-06-12T21:21:09.624392', 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'session': 'A53E01A4C04342AA84B2F304A859EF18', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'B856D63C29C847D79CAD08338080828B', 'msg_type': 'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method InteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\"\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"parameters = {'n_estimators':[10, 20, 30], 'clas...sifier(), parameters, 'random forest classifier')\", store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-294-26b1cb07d3bb>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n   2830                 code = compiler(mod, cell_name, \"single\")\n-> 2831                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000022796E7EAE0, file \"<ipython-input-294-26b1cb07d3bb>\", line 3>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2832                     return True\n   2833 \n   2834             # Flush softspace\n   2835             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000022796E7EAE0, file \"<ipython-input-294-26b1cb07d3bb>\", line 3>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000022796E7EAE0, file \"<ipython-input-294-26b1cb07d3bb>\", line 3>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", '# !pip install vk # makes it quiet\\nimport vk', 'vk_session = vk.Session() # starting new session\\nvk_api = vk.API(vk_session)', \"selected_group = 'hse_overheard' # no other idea... of posts in selected group: ', posts_number - 1)\", 'def load_all_posts(page, n_posts, api):\\n    all_...len(s) - 1 # update n_loaded\\n    return all_posts', \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", '# !pip install pymorphy2 -q # silent install aga...from IPython.display import display # progressbar', 'def split_text(text):\\n    tokenizer = TweetToken...ltered_words) # joining words to a sentence again', \"def convert_posts(posts_list):\\n    progress = In...ion = 'Done convertion!'\\n    return updated_posts\", 'converted_posts = convert_posts(loaded_posts)', 'import pandas as pd', 'posts_frame = pd.DataFrame(converted_posts)\\nposts_frame.head()', 'posts_frame.describe()', \"from sklearn.feature_extraction.text import Coun...columns\\nvalue_frame = posts_frame['likes_number']\", 'train_frame.describe()', \"# train_frame.to_csv('traindata.csv')\", 'from sklearn.cross_validation import train_test_...ame, value_frame, test_size=0.3, random_state=42)', ...], 'IntProgress': <class 'ipywidgets.widgets.widget_int.IntProgress'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, 'Out': {14:    likes_number  pinned  post_hour  post_month  ...    0  \n3                0  \n4                0  , 15:        likes_number  pinned   post_hour  post_mo...  0.00000  \nmax     2270.00000          1.00000  , 17:        pinned   post_hour  post_month     repost...  1.000000    1.000000  \n\n[8 rows x 4031 columns], 25: 0.0068924852394986564, 27: 0.018093065218199256, 28: {'alpha': 1, 'normalize': False, 'positive': True, 'selection': 'cyclic'}, 30: -9962768471560722.0, 34: -9962768471560722.0, 39: dict_keys(['max_leaf_nodes', 'class_weight', 'pr...min_samples_split', 'random_state', 'criterion']), 40: 0.2742857142857143, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'Ridge': <class 'sklearn.linear_model.ridge.Ridge'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", '# !pip install vk # makes it quiet\\nimport vk', 'vk_session = vk.Session() # starting new session\\nvk_api = vk.API(vk_session)', \"selected_group = 'hse_overheard' # no other idea... of posts in selected group: ', posts_number - 1)\", 'def load_all_posts(page, n_posts, api):\\n    all_...len(s) - 1 # update n_loaded\\n    return all_posts', \"try:\\n    loaded_posts = load_all_posts(page=sele...n to occur\\n    print('Error occured! Try again.')\", '# !pip install pymorphy2 -q # silent install aga...from IPython.display import display # progressbar', 'def split_text(text):\\n    tokenizer = TweetToken...ltered_words) # joining words to a sentence again', \"def convert_posts(posts_list):\\n    progress = In...ion = 'Done convertion!'\\n    return updated_posts\", 'converted_posts = convert_posts(loaded_posts)', 'import pandas as pd', 'posts_frame = pd.DataFrame(converted_posts)\\nposts_frame.head()', 'posts_frame.describe()', \"from sklearn.feature_extraction.text import Coun...columns\\nvalue_frame = posts_frame['likes_number']\", 'train_frame.describe()', \"# train_frame.to_csv('traindata.csv')\", 'from sklearn.cross_validation import train_test_...ame, value_frame, test_size=0.3, random_state=42)', ...], 'IntProgress': <class 'ipywidgets.widgets.widget_int.IntProgress'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, 'Out': {14:    likes_number  pinned  post_hour  post_month  ...    0  \n3                0  \n4                0  , 15:        likes_number  pinned   post_hour  post_mo...  0.00000  \nmax     2270.00000          1.00000  , 17:        pinned   post_hour  post_month     repost...  1.000000    1.000000  \n\n[8 rows x 4031 columns], 25: 0.0068924852394986564, 27: 0.018093065218199256, 28: {'alpha': 1, 'normalize': False, 'positive': True, 'selection': 'cyclic'}, 30: -9962768471560722.0, 34: -9962768471560722.0, 39: dict_keys(['max_leaf_nodes', 'class_weight', 'pr...min_samples_split', 'random_state', 'criterion']), 40: 0.2742857142857143, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'Ridge': <class 'sklearn.linear_model.ridge.Ridge'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\bulga\\Dropbox\\Учеба\\ВШЭ\\Майнор\\HSE_DataMiningHW\\DataAnalysis\\Homeworks\\Solutions\\Project\\Part 2\\<ipython-input-294-26b1cb07d3bb> in <module>()\n      1 \n      2 \n----> 3 \n      4 parameters = {'n_estimators':[10, 20, 30], 'class_weight':['balanced', 'balanced_subsample', None],\n      5              'max_features':['auto', 'sqrt', 'log2', None]}\n      6 compare(RandomForestClassifier(), parameters, 'random forest classifier')\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\bulga\\Dropbox\\Учеба\\ВШЭ\\Майнор\\HSE_DataMiningHW\\DataAnalysis\\Homeworks\\Solutions\\Project\\Part 2\\<ipython-input-269-b41b5f451bc3> in compare(est=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), param={'class_weight': ['balanced', 'balanced_subsample', None], 'max_features': ['auto', 'sqrt', 'log2', None], 'n_estimators': [10, 20, 30]}, est_name='random forest classifier')\n      1 \n      2 \n----> 3 \n      4 def compare(est, param, est_name):\n      5     cv = GridSearchCV(est, param, n_jobs = -1)\n      6     cv.fit(X_train, y_train);\n      7     print('CV best score for', est_name, ': ', cv.best_score_)\n      8     \n      9     predicted = cv.predict(X_test)\n     10     mse = mean_squared_error(y_test, predicted)\n     11     print('MSE for', est_name, ':' , mse)\n     12     r2 = r2_score(y_test, predicted)\n     13     print('R^2 for', est_name, ':' , r2)    \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=      pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], y=485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64)\n    799         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    800             Target relative to X for classification or regression;\n    801             None for unsupervised learning.\n    802 \n    803         \"\"\"\n--> 804         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X =       pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns]\n        y = 485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64\n        self.param_grid = {'class_weight': ['balanced', 'balanced_subsample', None], 'max_features': ['auto', 'sqrt', 'log2', None], 'n_estimators': [10, 20, 30]}\n    805 \n    806 \n    807 class RandomizedSearchCV(BaseSearchCV):\n    808     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=      pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], y=485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    548         )(\n    549             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    550                                     train, test, self.verbose, parameters,\n    551                                     self.fit_params, return_parameters=True,\n    552                                     error_score=self.error_score)\n--> 553                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    554                 for train, test in cv)\n    555 \n    556         # Out is a list of triplet: score, estimator, n_test_samples\n    557         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 12 21:21:37 2016\nPID: 1632                 Python 3.5.1: C:\\Users\\bulga\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], 485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, <function _passthrough_scorer>, array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), 0, {'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),       pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], 485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, <function _passthrough_scorer>, array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), 0, {'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=      pinned  post_hour  post_month  repost  sig...   0.0  \n1126   0.0  \n\n[1050 rows x 1007 columns], y=485      17\n527       5\n199       2\n889      16\n...  44\n1126     18\nName: likes_number, dtype: int64, scorer=<function _passthrough_scorer>, train=array([  86,  163,  191,  214,  215,  235,  259,...1043, 1044, 1045, 1046, 1047, 1048,\n       1049]), test=array([   0,    1,    2,    3,    4,    5,    6,... 951,  952,  958,\n        986,  987, 1012, 1038]), verbose=0, parameters={'class_weight': 'balanced_subsample', 'max_features': 'auto', 'n_estimators': 10}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1526 \n   1527     try:\n   1528         if y_train is None:\n   1529             estimator.fit(X_train, **fit_params)\n   1530         else:\n-> 1531             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None, verbose=0,\n            warm_start=False)>\n        X_train =       pinned  post_hour  post_month  repost  sig...000  \n1126  0.000000  \n\n[650 rows x 1007 columns]\n        y_train = 1387     73\n1478    150\n915      73\n638      16\n...  44\n1126     18\nName: likes_number, dtype: int64\n        fit_params = {}\n   1532 \n   1533     except Exception as e:\n   1534         if error_score == 'raise':\n   1535             raise\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), sample_weight=None)\n    285             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    286                              backend=\"threading\")(\n    287                 delayed(_parallel_build_trees)(\n    288                     t, self, X, y, sample_weight, i, len(trees),\n    289                     verbose=self.verbose, class_weight=self.class_weight)\n--> 290                 for i, t in enumerate(trees))\n        i = 9\n    291 \n    292             # Collect newly grown trees\n    293             self.estimators_.extend(trees)\n    294 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    795         self._smoothed_batch_duration = 0.0\n    796         try:\n    797             # Only set self._iterating to True if at least a batch\n    798             # was dispatched. In particular this covers the edge\n    799             # case of Parallel used with an exhausted iterator.\n--> 800             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    801                 self._iterating = True\n    802             else:\n    803                 self._iterating = False\n    804 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    653             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    654             if not tasks:\n    655                 # No more tasks available in the iterator: tell caller to stop.\n    656                 return False\n    657             else:\n--> 658                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    659                 return True\n    660 \n    661     def _print(self, msg, msg_args):\n    662         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    561         # If job.get() catches an exception, it closes the queue:\n    562         if self._aborting:\n    563             return\n    564 \n    565         if self._pool is None:\n--> 566             job = ImmediateComputeBatch(batch)\n        job = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    567             self._jobs.append(job)\n    568             self.n_dispatched_batches += 1\n    569             self.n_dispatched_tasks += len(batch)\n    570             self.n_completed_tasks += len(batch)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __init__(self=<sklearn.externals.joblib.parallel.ImmediateComputeBatch object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    175 \n    176     \"\"\"\n    177     def __init__(self, batch):\n    178         # Don't delay the application, to avoid keeping the input\n    179         # arguments in memory\n--> 180         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    181 \n    182     def get(self):\n    183         return self.results\n    184 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), None, 0, 10), {'class_weight': 'balanced_subsample', 'verbose': 0})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), None, 0, 10)\n        kwargs = {'class_weight': 'balanced_subsample', 'verbose': 0}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=608667729, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[  0.,  15.,   1., ...,   0.,   0.,   0.]...1.,   2., ...,   0.,   0.,   0.]], dtype=float32), y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), sample_weight=None, tree_idx=0, n_trees=10, verbose=0, class_weight='balanced_subsample')\n    109         if class_weight == 'subsample':\n    110             with warnings.catch_warnings():\n    111                 warnings.simplefilter('ignore', DeprecationWarning)\n    112                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    113         elif class_weight == 'balanced_subsample':\n--> 114             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n        curr_sample_weight = array([ 0.,  1.,  1.,  1.,  0.,  0.,  2.,  3.,  ...1.,  1.,  3.,  1.,  0.,  2.,  0.,  2.,  3.,  0.])\n        y = array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]])\n        indices = array([286,  41, 345, 507, 409, 232, 108,   2, 3...26, 453, 648, 290, 195, 523, 562, 453, 551, 103])\n    115 \n    116         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n    117     else:\n    118         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py in compute_sample_weight(class_weight='balanced', y=array([[ 65.],\n       [ 74.],\n       [ 65.],\n   ....],\n       [ 39.],\n       [ 44.],\n       [ 18.]]), indices=array([286,  41, 345, 507, 409, 232, 108,   2, 3...26, 453, 648, 290, 195, 523, 562, 453, 551, 103]))\n    157             weight_k = np.choose(np.searchsorted(classes_subsample,\n    158                                                  classes_full),\n    159                                  compute_class_weight(class_weight_k,\n    160                                                       classes_subsample,\n    161                                                       y_subsample),\n--> 162                                  mode='clip')\n    163 \n    164             classes_missing = set(classes_full) - set(classes_subsample)\n    165         else:\n    166             weight_k = compute_class_weight(class_weight_k,\n\n...........................................................................\nC:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in choose(a=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1...    62, 62, 63, 64, 65, 66, 67, 68], dtype=int64), choices=array([ 0.08722491,  0.17444981,  0.21907651,  0...42028986,  9.42028986,  9.42028986,  9.42028986]), out=None, mode='clip')\n    346     \"\"\"\n    347     try:\n    348         choose = a.choose\n    349     except AttributeError:\n    350         return _wrapit(a, 'choose', choices, out=out, mode=mode)\n--> 351     return choose(choices, out=out, mode=mode)\n        choose = <built-in method choose of numpy.ndarray object>\n        choices = array([ 0.08722491,  0.17444981,  0.21907651,  0...42028986,  9.42028986,  9.42028986,  9.42028986])\n        out = None\n        mode = 'clip'\n    352 \n    353 \n    354 def repeat(a, repeats, axis=None):\n    355     \"\"\"\n\nValueError: Need between 2 and (32) array objects (inclusive).\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[10, 20, 30], 'class_weight':['balanced', 'balanced_subsample', None],\n",
    "             'max_features':['auto', 'sqrt', 'log2', None]}\n",
    "compare(RandomForestClassifier(), parameters, 'random forest classifier')\n",
    "# 'max_depth': np.arange(2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bulga\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best score for kNN :  0.150476190476\n",
      "MSE for kNN : 1027.62666667\n",
      "R^2 for kNN : -0.11098810364\n"
     ]
    }
   ],
   "source": [
    "parameters = {'leaf_size':np.arange(30, 100, 10),'n_neighbors': np.arange(5, 20), \n",
    "              'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "compare(KNeighborsClassifier(), parameters, 'kNN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data analysis project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_In this project I am going to write a program to predict the number likes post is going to get in vk._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Выполнил__: Булгаков Дмитрий (ИАД16)\n",
    "\n",
    "__Дедлайн__: 23:59 19.06.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "VK library quiet installation and import into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install vk # makes it quiet\n",
    "import vk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Starting new vk session in order to parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vk_session = vk.Session() # starting new session\n",
    "vk_api = vk.API(vk_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Getting number of posts in selected vk group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts in selected group:  13977\n"
     ]
    }
   ],
   "source": [
    "selected_group = 'hse_overheard' # no other ideas :c\n",
    "posts_number = vk_api.wall.get(domain=selected_group)[0] # number of posts is stored in first element\n",
    "print('Number of posts in selected group: ', posts_number - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Writing a function to parse more, than 100 posts from group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all_posts(page, n_posts, api):\n",
    "    all_posts = api.wall.get(domain=page, count=n_posts)\n",
    "    n_loaded = len(all_posts)\n",
    "    while n_loaded < n_posts: # loop to load more, than 100 posts\n",
    "        s = api.wall.get(domain=page, offset=n_loaded, count=(n_posts - n_loaded)) # update offset\n",
    "        all_posts += s[1:] # no need for first element\n",
    "        n_loaded += len(s) - 1 # update n_loaded\n",
    "    return all_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading all posts from group for future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded posts:  1250\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    loaded_posts = load_all_posts(page=selected_group, n_posts=1251, api=vk_api)[1:] # no need for posts number element\n",
    "    print('Number of loaded posts: ', len(loaded_posts))\n",
    "except: # timout errors are often to occur\n",
    "    print('Error occured! Try again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading required libs to preprocess data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install pymorphy2 -q # silent install again\n",
    "# !pip install stop_words -q # needed to remove stop words\n",
    "from stop_words import get_stop_words\n",
    "import pymorphy2 # need this one to convert words to normal time\n",
    "import datetime # needed to convert response date \n",
    "import string # needed to work with strings\n",
    "from nltk.tokenize import TweetTokenizer # needed to split text\n",
    "import pandas as pd # required to work with dataframes\n",
    "from ipywidgets import IntProgress # progressbar\n",
    "from IPython.display import display # progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Writing functions to process text data. Converting words to normal form and removing punctuation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(text) # spliting text into words\n",
    "\n",
    "def convert_to_normal_form(words_list):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    normal_forms_list = []\n",
    "    for word in words_list:\n",
    "        if word not in string.punctuation and word[0] != \"<\":\n",
    "            norm_form = morph.parse(word)[0].normal_form #getting normal form of a word\n",
    "            normal_forms_list.append(norm_form) #adding it to list\n",
    "    return normal_forms_list\n",
    "\n",
    "def convert_text(text):\n",
    "    words_list = split_text(text) # spliting text into words\n",
    "    norm_words_list = convert_to_normal_form(words_list) # words into normal form\n",
    "    filtered_words = [w for w in norm_words_list if not w in get_stop_words('russian')] # removing stop words\n",
    "    return \" \".join(filtered_words) # joining words to a sentence again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Writing a function to convert received list into another with another data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_posttime(post, cur_date):\n",
    "    post_time = datetime.datetime.fromtimestamp(post['date'])\n",
    "    elapsed_time = (cur_date - post_time).seconds / 3600\n",
    "    elapsed_days = (cur_date - post_time).days\n",
    "    \n",
    "    if (elapsed_time < 1):\n",
    "        return 0\n",
    "    if (elapsed_time < 5):\n",
    "        return 1\n",
    "    if (elapsed_days < 1):\n",
    "        return 2\n",
    "    if (elapsed_days < 5):\n",
    "        return 3\n",
    "    if (elapsed_days < 10):\n",
    "        return 4\n",
    "    if (elapsed_days < 30):\n",
    "        return 5\n",
    "    if (elapsed_days < 90):\n",
    "        return 6\n",
    "    if (elapsed_days < 180):\n",
    "        return 7\n",
    "    if (elapsed_days < 365):\n",
    "        return 8\n",
    "    if (elapsed_days < 730):\n",
    "        return 9\n",
    "    return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_attachment(post):\n",
    "    tmp_dict = {'photo_attachment': 0, 'poll_attachment': 0, 'link_attachment': 0}\n",
    "    \n",
    "    if 'attachments' not in post.keys():\n",
    "        return tmp_dict\n",
    "    else:\n",
    "        for attachment in post['attachments']:\n",
    "            if attachment['type'] == 'photo':\n",
    "                tmp_dict['photo_attachment'] = 1\n",
    "            if attachment['type'] == 'poll':\n",
    "                tmp_dict['poll_attachment'] = 1\n",
    "            if attachment['type'] == 'link':\n",
    "                tmp_dict['link_attachment'] = 1\n",
    "        return tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_posts(posts_list):\n",
    "    progress = IntProgress() \n",
    "    progress.max = len(posts_list) # initializing progressbar\n",
    "    progress.description = 'Processing data convertion'\n",
    "    display(progress)\n",
    "    current_date = pd.datetime.today()\n",
    "    \n",
    "    updated_posts = [] # list of new posts' list structure\n",
    "    for i, post in enumerate(posts_list): \n",
    "        tmp_dict = {} # creating empty dictionary for each post\n",
    "        tmp_dict['likes_number'] = int(post['likes']['count']) # getting likes count\n",
    "        tmp_dict['post_text'] = convert_text(post['text']) # converting text into normal form\n",
    "        tmp_dict['long_text'] = 1 if len(post['text']) > 400 else 0 # calculating text length\n",
    "        post_date = datetime.datetime.fromtimestamp(post['date'])\n",
    "        tmp_dict['post_hour'] = int(post_date.strftime('%H')) # parsing only post hour\n",
    "        tmp_dict['post_month'] = int(post_date.strftime('%m')) # and post month\n",
    "        # tmp_dict['signed'] = int(post['from_id'] != -57354358) # checking whether post is signed or not\n",
    "        # checking if any attacment exists\n",
    "        tmp_dict['time_elapsed'] = check_posttime(post, current_date)\n",
    "        tmp_dict.update(check_attachment(post))\n",
    "        tmp_dict['near_exam_week'] = 1 if post_date.month in [10, 12, 3, 6] else 0\n",
    "        # tmp_dict['pinned'] = 1 if 'is_pinned' in post.keys() else 0 # cheking if post is pinned\n",
    "        updated_posts.append(tmp_dict)\n",
    "        progress.value += 1 # increasing progressbar value\n",
    "    progress.description = 'Done convertion!'\n",
    "    return updated_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Converting list of posts into new more convenient one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "converted_posts = convert_posts(loaded_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Creating object-feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframe from parsed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes_number</th>\n",
       "      <th>link_attachment</th>\n",
       "      <th>long_text</th>\n",
       "      <th>near_exam_week</th>\n",
       "      <th>photo_attachment</th>\n",
       "      <th>poll_attachment</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>post_month</th>\n",
       "      <th>post_text</th>\n",
       "      <th>time_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>заслуживать мнение россия отстранение олимпиад...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>китаец получить большинство право приход дэн с...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>конкурс « подслушать » вместе билайн продолжат...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>чей лошадка победить мисс ниу вшэ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>писать сюда придумать способ найти эконом гей ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   likes_number  link_attachment  long_text  near_exam_week  photo_attachment  \\\n",
       "0             0                0          0               1                 0   \n",
       "1             0                0          0               1                 0   \n",
       "2             0                1          1               1                 1   \n",
       "3             2                0          0               1                 0   \n",
       "4             9                0          1               1                 0   \n",
       "\n",
       "   poll_attachment  post_hour  post_month  \\\n",
       "0                1         12           6   \n",
       "1                0         11           6   \n",
       "2                0         15           6   \n",
       "3                0         10           6   \n",
       "4                1          9           6   \n",
       "\n",
       "                                           post_text  time_elapsed  \n",
       "0  заслуживать мнение россия отстранение олимпиад...             2  \n",
       "1  китаец получить большинство право приход дэн с...             2  \n",
       "2  конкурс « подслушать » вместе билайн продолжат...             3  \n",
       "3                  чей лошадка победить мисс ниу вшэ             3  \n",
       "4  писать сюда придумать способ найти эконом гей ...             3  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_frame = pd.DataFrame(converted_posts)\n",
    "posts_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And describing posts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes_number</th>\n",
       "      <th>link_attachment</th>\n",
       "      <th>long_text</th>\n",
       "      <th>near_exam_week</th>\n",
       "      <th>photo_attachment</th>\n",
       "      <th>poll_attachment</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>post_month</th>\n",
       "      <th>time_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1250.00000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.28640</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.17520</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>15.320000</td>\n",
       "      <td>4.288800</td>\n",
       "      <td>4.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27.84688</td>\n",
       "      <td>0.105278</td>\n",
       "      <td>0.363001</td>\n",
       "      <td>0.451117</td>\n",
       "      <td>0.38029</td>\n",
       "      <td>0.160386</td>\n",
       "      <td>6.046788</td>\n",
       "      <td>1.296896</td>\n",
       "      <td>2.509514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>249.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       likes_number  link_attachment    long_text  near_exam_week  \\\n",
       "count    1250.00000      1250.000000  1250.000000     1250.000000   \n",
       "mean       16.28640         0.011200     0.156000        0.284000   \n",
       "std        27.84688         0.105278     0.363001        0.451117   \n",
       "min         0.00000         0.000000     0.000000        0.000000   \n",
       "25%         1.00000         0.000000     0.000000        0.000000   \n",
       "50%         6.00000         0.000000     0.000000        0.000000   \n",
       "75%        18.00000         0.000000     0.000000        1.000000   \n",
       "max       249.00000         1.000000     1.000000        1.000000   \n",
       "\n",
       "       photo_attachment  poll_attachment    post_hour   post_month  \\\n",
       "count        1250.00000      1250.000000  1250.000000  1250.000000   \n",
       "mean            0.17520         0.026400    15.320000     4.288800   \n",
       "std             0.38029         0.160386     6.046788     1.296896   \n",
       "min             0.00000         0.000000     0.000000     2.000000   \n",
       "25%             0.00000         0.000000    12.000000     3.000000   \n",
       "50%             0.00000         0.000000    16.000000     5.000000   \n",
       "75%             0.00000         0.000000    20.000000     5.000000   \n",
       "max             1.00000         1.000000    23.000000     6.000000   \n",
       "\n",
       "       time_elapsed  \n",
       "count   1250.000000  \n",
       "mean       4.124000  \n",
       "std        2.509514  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        5.000000  \n",
       "75%        6.000000  \n",
       "max        7.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Creating object-feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer # loading count vectorizer\n",
    "\n",
    "cv = TfidfVectorizer(norm='l1', max_features = 200, analyzer = 'word', strip_accents='unicode', binary=True)\n",
    "train_features = cv.fit_transform(posts_frame['post_text']).toarray() # vectorizing texts\n",
    "train_frame = posts_frame.join(pd.DataFrame(train_features, columns=cv.get_feature_names())) # transfering it to pandas\n",
    "all_data = train_frame.copy()\n",
    "train_frame.drop(['likes_number','post_text'],inplace=True,axis=1,errors='ignore') # removing unnecessary columns\n",
    "value_frame = posts_frame['likes_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_attachment</th>\n",
       "      <th>long_text</th>\n",
       "      <th>near_exam_week</th>\n",
       "      <th>photo_attachment</th>\n",
       "      <th>poll_attachment</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>post_month</th>\n",
       "      <th>time_elapsed</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>ходить</th>\n",
       "      <th>хорошии</th>\n",
       "      <th>хотеться</th>\n",
       "      <th>читать</th>\n",
       "      <th>что</th>\n",
       "      <th>школа</th>\n",
       "      <th>экзамен</th>\n",
       "      <th>эконом</th>\n",
       "      <th>экономика</th>\n",
       "      <th>язык</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.17520</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>15.320000</td>\n",
       "      <td>4.288800</td>\n",
       "      <td>4.124000</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>0.004014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.105278</td>\n",
       "      <td>0.363001</td>\n",
       "      <td>0.451117</td>\n",
       "      <td>0.38029</td>\n",
       "      <td>0.160386</td>\n",
       "      <td>6.046788</td>\n",
       "      <td>1.296896</td>\n",
       "      <td>2.509514</td>\n",
       "      <td>0.046419</td>\n",
       "      <td>0.022859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047565</td>\n",
       "      <td>0.062114</td>\n",
       "      <td>0.030094</td>\n",
       "      <td>0.026595</td>\n",
       "      <td>0.028267</td>\n",
       "      <td>0.039444</td>\n",
       "      <td>0.054575</td>\n",
       "      <td>0.040948</td>\n",
       "      <td>0.035494</td>\n",
       "      <td>0.039532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514109</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347636</td>\n",
       "      <td>0.507462</td>\n",
       "      <td>0.384452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557453</td>\n",
       "      <td>0.534517</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       link_attachment    long_text  near_exam_week  photo_attachment  \\\n",
       "count      1250.000000  1250.000000     1250.000000        1250.00000   \n",
       "mean          0.011200     0.156000        0.284000           0.17520   \n",
       "std           0.105278     0.363001        0.451117           0.38029   \n",
       "min           0.000000     0.000000        0.000000           0.00000   \n",
       "25%           0.000000     0.000000        0.000000           0.00000   \n",
       "50%           0.000000     0.000000        0.000000           0.00000   \n",
       "75%           0.000000     0.000000        1.000000           0.00000   \n",
       "max           1.000000     1.000000        1.000000           1.00000   \n",
       "\n",
       "       poll_attachment    post_hour   post_month  time_elapsed           10  \\\n",
       "count      1250.000000  1250.000000  1250.000000   1250.000000  1250.000000   \n",
       "mean          0.026400    15.320000     4.288800      4.124000     0.004544   \n",
       "std           0.160386     6.046788     1.296896      2.509514     0.046419   \n",
       "min           0.000000     0.000000     2.000000      0.000000     0.000000   \n",
       "25%           0.000000    12.000000     3.000000      1.000000     0.000000   \n",
       "50%           0.000000    16.000000     5.000000      5.000000     0.000000   \n",
       "75%           0.000000    20.000000     5.000000      6.000000     0.000000   \n",
       "max           1.000000    23.000000     6.000000      7.000000     1.000000   \n",
       "\n",
       "                20     ...            ходить      хорошии     хотеться  \\\n",
       "count  1250.000000     ...       1250.000000  1250.000000  1250.000000   \n",
       "mean      0.002171     ...          0.005434     0.010823     0.004462   \n",
       "std       0.022859     ...          0.047565     0.062114     0.030094   \n",
       "min       0.000000     ...          0.000000     0.000000     0.000000   \n",
       "25%       0.000000     ...          0.000000     0.000000     0.000000   \n",
       "50%       0.000000     ...          0.000000     0.000000     0.000000   \n",
       "75%       0.000000     ...          0.000000     0.000000     0.000000   \n",
       "max       0.514109     ...          1.000000     1.000000     0.347636   \n",
       "\n",
       "            читать          что        школа      экзамен       эконом  \\\n",
       "count  1250.000000  1250.000000  1250.000000  1250.000000  1250.000000   \n",
       "mean      0.002397     0.004249     0.004348     0.005387     0.004833   \n",
       "std       0.026595     0.028267     0.039444     0.054575     0.040948   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.507462     0.384452     1.000000     1.000000     0.557453   \n",
       "\n",
       "         экономика         язык  \n",
       "count  1250.000000  1250.000000  \n",
       "mean      0.004959     0.004014  \n",
       "std       0.035494     0.039532  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       0.000000     0.000000  \n",
       "max       0.534517     1.000000  \n",
       "\n",
       "[8 rows x 208 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_frame = scaler.fit_transform(train_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving train frame to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_frame.to_csv('traindata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Comparing different methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Splitting it into test and train samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_frame, value_frame, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare(est, param, est_name):\n",
    "    cv = GridSearchCV(est, param, n_jobs = -1, scoring = 'r2')\n",
    "    cv.fit(X_train, y_train);\n",
    "    print('CV best score for', est_name, ': ', cv.best_score_,'. (R^2)')\n",
    "    \n",
    "    # predicted = cv.predict(X_test)\n",
    "    # mse = mean_squared_error(y_test, predicted)\n",
    "    # print('MSE for', est_name, ':' , mse)\n",
    "    # r2 = r2_score(y_test, predicted)\n",
    "    # print('R^2 for', est_name, ':' , r2)\n",
    "    \n",
    "    print('Getting best params: ')\n",
    "    print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best score for simple linear regression :  0.0813882291522 . (R^2)\n",
      "Getting best params: \n",
      "{'fit_intercept': True, 'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'fit_intercept':[True, False],'normalize':[True, False]}\n",
    "compare(LinearRegression(), parameters, 'simple linear regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Linear regression with L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best score for linear regression with L1 regularization :  0.375652950012 . (R^2)\n",
      "Getting best params: \n",
      "{'selection': 'cyclic', 'positive': False, 'normalize': False, 'alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha':np.arange(1, 100, 5), 'positive':[True, False],'normalize':[True, False], \n",
    "              'selection':['cyclic', 'random']}\n",
    "compare(Lasso(), parameters, 'linear regression with L1 regularization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Linear regression with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best score for linear regression with L2 regularization :  0.337826803014 . (R^2)\n",
      "Getting best params: \n",
      "{'solver': 'sag', 'fit_intercept': True, 'normalize': False, 'alpha': 338.84415613920277}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha':np.logspace(1.0, 10.0, 101.00), 'fit_intercept':[True, False],'normalize':[True, False],\n",
    "              'solver':['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'auto']}\n",
    "compare(Ridge(), parameters, 'linear regression with L2 regularization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Decision trees and random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best score for decision tree classifier :  0.358506150346 . (R^2)\n",
      "Getting best params: \n",
      "{'max_features': None, 'splitter': 'random', 'presort': True, 'max_depth': 2}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'presort':[True, False],'max_depth': np.arange(1, 20), 'splitter':['random', 'best'],\n",
    "             'max_features':['auto', 'sqrt', 'log2', None]}\n",
    "compare(tree.DecisionTreeRegressor(), parameters, 'decision tree classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best score for random forest classifier :  0.217789808791 . (R^2)\n",
      "Getting best params: \n",
      "{'max_features': 'log2', 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[10, 20, 30],\n",
    "             'max_features':['auto', 'sqrt', 'log2', None]}\n",
    "compare(RandomForestRegressor(), parameters, 'random forest classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best score for kNN :  0.32390121803 . (R^2)\n",
      "Getting best params: \n",
      "{'n_neighbors': 14, 'algorithm': 'auto', 'leaf_size': 30}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'leaf_size':np.arange(30, 100, 10),'n_neighbors': np.arange(5, 20), \n",
    "              'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "compare(KNeighborsRegressor(), parameters, 'kNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Best prediction is with linear regression with L2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Optimizing Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls = Lasso(selection='random', alpha=1, normalize=False, positive=False)\n",
    "ls.fit(X_train, y_train);\n",
    "y_pred = ls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel = 'Real values'\n",
    "plt.ylabel = 'Predict values'\n",
    "plt.show()\n",
    "\n",
    "print('MAE: ', metr.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = all_data.iloc[:,0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 10))\n",
    "all_data.drop(['post_text'], inplace=True,axis=1,errors='ignore') \n",
    "for idx, feature in enumerate(data.columns[:-1]):\n",
    "    data.plot(feature, 'likes_number', subplots=True, kind='scatter', ax=axes[idx / 4, idx % 4])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет по выполнению домашнего задания #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Дата выдачи__: 24.02.2016\n",
    "\n",
    "__Дедлайн__: 23:59 12.03.2016\n",
    "\n",
    "__Выполнил__: Булгаков Дмитрий (ИАД16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc as sc\n",
    "import sklearn\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_text(s):\n",
    "    # Removes all characters from string except letters and digits and convert letters to lowercase\n",
    "    return re.sub(\"[^a-zA-Z0-9]\", \" \", s.lower())\n",
    "\n",
    "def read_txts(dir_path=\"./txt_sentoken/pos/\"):\n",
    "    # Reads all files from directory\n",
    "    if dir_path[-1] != \"/\":\n",
    "        dir_path = dir_path + \"/\"\n",
    "    txt_list = []\n",
    "    for file in os.listdir(dir_path):\n",
    "        file = dir_path + file\n",
    "        fin = open(file, 'r')\n",
    "        txt = \" \".join(fin.readlines())\n",
    "        txt = convert_text(txt)\n",
    "        txt_list.append(txt)\n",
    "    return txt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PoissonNB:\n",
    "    def __init__(self, class_prior=None):\n",
    "        \"\"\"\n",
    "        class_prior : np.array, size (n_classes,)\n",
    "        Prior probabilities of the classes. If specified the priors are not\n",
    "        adjusted according to the data.\n",
    "        \"\"\"\n",
    "        self.class_prior = class_prior\n",
    "        \n",
    "        # checking data input to constructor\n",
    "        if self.class_prior is not None:\n",
    "            self.class_prior_pre = True\n",
    "        else:\n",
    "            self.class_prior_pre = False\n",
    "    \n",
    "    def fit(self, X, y, epsilon=1e-9):\n",
    "        \"\"\"\n",
    "        Fit Poisson Naive Bayes according to X, y\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array, shape (n_samples, n_features)\n",
    "            Training vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : np.array, shape (n_samples,)\n",
    "            Target values.\n",
    "        \"\"\"\n",
    "        # finding classes vector (we need uniq only)\n",
    "        self.class_vector = np.unique(y)\n",
    "        # getting number of claseses\n",
    "        self.class_number = self.class_vector.shape[0]\n",
    "        # getting number of samples and features\n",
    "        samples_number, features_number = X.shape\n",
    "        \n",
    "        # creating empty array(s) for calucations\n",
    "        self.lambda_matrix = np.zeros((self.class_number, features_number))\n",
    "        self.lambda_matrix.fill(epsilon)\n",
    "        \n",
    "        if not self.class_prior_pre:\n",
    "            self.class_prior = np.zeros(self.class_number)\n",
    "        \n",
    "        # calculating prior propability matrix and lambda matrix\n",
    "        for i, y_i in enumerate(self.class_vector):\n",
    "            # finding elements in iterated class\n",
    "            Xi = X[y_i == y]\n",
    "            # only in case not present in constructor\n",
    "            if not self.class_prior_pre:\n",
    "                # calculating propbalitities for each class (assuming uniform distribution)\n",
    "                self.class_prior[i] = Xi.shape[0] / samples_number\n",
    "            # calculating lambdas matrix for next calucaltions (by formula from the task descr)\n",
    "            self.lambda_matrix[i] += np.mean(Xi, axis=0)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Perform classification on an array of test vectors X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array, shape = [n_samples, n_features]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        C : np.array, shape = [n_samples]\n",
    "            Predicted target values for X\n",
    "        \"\"\"\n",
    "        # creating empty likehood matrix\n",
    "        likehood_matrix = np.zeros((np.shape(X)[0], np.size(self.class_vector)))\n",
    "        \n",
    "        # calculating likehood matrix\n",
    "        for i in range(self.class_number):\n",
    "            # log of value due to small values\n",
    "            c_prior = np.log(self.class_prior[i])\n",
    "            \n",
    "            # calculating propability function (by formula for Poisson distr)\n",
    "            p_ij = np.sum(X * np.log(self.lambda_matrix[i]), axis=1) - np.sum(self.lambda_matrix[i]) - np.log(sc.factorial(X)).shape[0]\n",
    "           \n",
    "            # calculating by formula from task descr, '*' to '+' because logarithm usage\n",
    "            likehood_matrix[:, i] = c_prior + p_ij\n",
    "            \n",
    "        avector = np.argmax(likehood_matrix, axis=1)\n",
    "        return self.class_vector[avector]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Решение задачи:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__#1.__ Загрузите и преобразуйте данные с помощью функции read_txts() из выданного ноутбука. В итоге\n",
    "\n",
    "должно получиться два списка: с положительными и с отрицательными рецензиями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_rev = read_txts(\"./txt_sentoken/pos/\")\n",
    "neg_rev = read_txts(\"./txt_sentoken/neg/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__#2__ Из всех рецензий сформируйте два списка: тексты для обучающей выборки (по 700 случайных каж-\n",
    "\n",
    "дого класса) и для контрольной выборки (по 300 оставшихся), а также вектор правильных ответов\n",
    "\n",
    "для обучающей и контрольной выборки. Например, положительные рецензии можно относить к\n",
    "\n",
    "классу «1», а отрицательные — к классу «0»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.hstack((pos_rev, neg_rev))\n",
    "y = np.ones(len(pos_rev) + len(neg_rev))\n",
    "y[len(pos_rev):] = 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__#3__ Прочитайте, как работает класс sklearn.feature_extraction.text.CountVectorizer, и с его помощью со-\n",
    "\n",
    "здайте две матрицы «объекты × признаки»: для обучающей и контрольной выборки. Учтите, что\n",
    "\n",
    "CountVectorizer.transform возвращает разреженную матрицу — чтобы преобразовать её к знакомому\n",
    "\n",
    "нам np.array, воспользуйтесь функцией .toarray()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "train_features = cv.fit_transform(X_train).toarray()\n",
    "test_features = cv.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__#4__ Сами реализуйте класс PoissonNB, реализующий пуассоновский наивный байесовский классифи-\n",
    "\n",
    "катор. Методы, которые должны быть реализованы в этом классе, описаны в jupyter ноутбуке,\n",
    "\n",
    "выданном вместе с заданием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pnb = PoissonNB()\n",
    "pnb.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__#5__ Протестируйте ваш классификатор на данных и посчитайте accuracy — долю правильных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Poisson naive Bayes classificator is  70.6666666667 %\n"
     ]
    }
   ],
   "source": [
    "res_test = pnb.predict(test_features)\n",
    "pnb_accuracy = np.mean(y_test == res_test)\n",
    "print('Accuracy for Poisson naive Bayes classificator is ', pnb_accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "__#6__ Протестируйте мультиномиальный и гауссовский наивный байесовский классификатор, реализованный в библиотеке scikit-learn (в sklearn.naive_bayes). Можно использовать параметры по умолчанию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Multinominal classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_features, y_train)\n",
    "res_test = mnb.predict(test_features)\n",
    "mnb_accuracy = np.mean(y_test==res_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(train_features, y_train)\n",
    "res_test = gnb.predict(test_features)\n",
    "gnb_accuracy = np.mean(y_test==res_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multinominal naive Bayes classificator is  81.8333333333 %\n",
      "Accuracy for Gaussian naive Bayes classificator is  64.6666666667 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for Multinominal naive Bayes classificator is ', mnb_accuracy * 100, \"%\")\n",
    "print('Accuracy for Gaussian naive Bayes classificator is ', gnb_accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__#7__ Напишите функцию, которая принимает на вход строку с текстом рецензии, обученный классифи-\n",
    "\n",
    "катор, обученный объект класса CountVectorizer и печатает, положительна ли данная рецензия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_estimate(text, classificator, count_vect):\n",
    "    text = convert_text(text)\n",
    "    text = count_vect.transform([text]).toarray()\n",
    "    if classificator.predict(text):\n",
    "        print('positive')\n",
    "    else:\n",
    "        print('negative')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampletext = '''An incredible journey that began a decade ago finally arrives at its close with David Yates' \"Harry Potter and the Deathly Hallows: Part II\", as 'The Boy Who Lived' comes face to face with 'He Who Shall Not Be Named' in an epic showdown between good and evil. And what a showdown it is- tense, thrilling, breathtaking, and fitting of just about any superlative you can think of. \n",
    "\n",
    "Whereas the first instalment of the 'Deathly Hallows' emphasised the profound sense of loss and isolation among Harry, Ron and Hermoine, screenwriter Steve Kloves and director Yates leaves behind the moody atmosphere of the previous movie for newfound immediacy and urgency. This is all about that final battle where only one can live, and from start to finish- for once in a Harry Potter movie- the action is swift and relentless.\n",
    "\n",
    "Part II picks up right where the previous film left off- the dark Lord Voldemort smiles in evil triumph as he steals the most powerful wand in the world, i.e. the Elder Wand, from the tomb of beloved Hogwarts headmaster Professor Dumbledore (Michael Gambon). The next shot is equally ominous- students are marched rank-and-file through a Hogwarts courtyard, watched closely by cloaked Dementors hovering over the school grounds. If there was any need of a reminder of the danger facing our three protagonists, these opening sequences should just about refresh one's memory of what is at stake.\n",
    "\n",
    "There is precious little time to waste, and the first we get to see Harry, Ron and Hermione, they are already hatching a plan to break into Gringotts to retrieve a Horcrux. Their break-in settles upon a plan of deception that allows for some rare moments of levity in the film, as Helena Bonham Carter gets to ham it up as a polyjuice-disguised Hermoine impersonating Bellatrix Lestrange. This being the first 'Harry Potter' movie in 3D, Yates caters for some distinctive thrills in the additional dimension with a roller-coaster ride through the vault, culminating in a daring escape on the back of a dragon.\n",
    "\n",
    "But as readers of the book will tell you, the last stand happens back at Hogwarts, and true enough, after this thrilling early set-piece at Gringotts, the trio head back to the School of Witchcraft and Wizardry to confront their foes. It is also where the last Horcruxes are supposed to be, and Harry's return to the once sunny and cheery grounds now besieged by darkness and doom becomes a true test of allegiance. \n",
    "\n",
    "Fans will be glad that Kloves gives room for otherwise supporting characters to step into the limelight- in particular, Neville Longbottom (Matthew Lewis) emerges as one of the unlikeliest but also truest heroes on the side of good. The Hogwarts stalwarts also get a chance to show off their magic, and Yates gives each largely enough screen time for the heroic send-off they deserve.\n",
    "\n",
    "Yet he reserves the most emotional moment in the film for Severus Snape's (Alan Rickman) vindication, long thought to be the Judas Iscariot-equivalent in the Order and the one who pushed Dumbledore to his death. Yates delivers a truly poignant and deeply heartfelt revelation of Snape's true colours, and it is a farewell that even those who have read the book and can expect what is to come will be overwhelmed by its sheer emotional muscle. While Part II was always meant to be an action-packed spectacle, it is to Yates' credit that there is still as much heart as before in the storytelling.\n",
    "\n",
    "Though brief, this revelation also works brilliantly as a catalyst that propels Harry to come to terms with the sacrifice he has to make. Harry's realization of this leads up perfectly to the ultimate duel between him and Voldemort, one that is fierce, ferocious and- thanks to Yates' imagination- more exhilarating than reading it off the page. \n",
    "\n",
    "The outcome of that battle shouldn't be a secret by now, and when the 'happily-ever-after' coda in Rowling's book set 19 years later is also faithfully adapted here, you can't quite help but be moved by how it so properly gives the series closure.\n",
    "\n",
    "They are of course no longer kids here- Daniel Radcliffe, Rupert Grint and Emma Watson now young adults who have through the film series grown up right under our eyes. While Part I had greater emphasis on Ron and Hermoine, the focus here is squarely on Harry and Radcliffe truly shines in this instalment- his usual understated performance allowing his audience to appreciate the enormities of the challenge before Harry.\n",
    "\n",
    "That we can be so fully immersed in Harry's world is testament to the craft of each and every one of the technical team. Production designer Stuart Craig does a masterful job portraying the devastation around Hogwarts, complimented nicely by Eduardo Serra's beautiful cinematography and Mark Day's skillful editing. Alexandre Desplat's evocative score, which combines his own elegiac work with both the John Williams theme as well as Nicholas Hooper's mournful composition for the sixth movie, works magic with the visuals. And most deserving of credit is none other than director Yates himself, who has matured movie after movie to deliver a crowning achievement for the series.\n",
    "\n",
    "Pardon us if we have also taken this opportunity to extol the merits of the 'Harry Potter' franchise- it's really hard not to considering how this is the last time we will see the Potter-world in its current incarnation. It is this to which the movie is a farewell to, and it is as beautiful a farewell as it can be, packed with visual spectacle on a scale never before seen in any of the other films and fused with the same powerful emotion as Part I and the Yates films before. All good- even great- things have to come to an end, so there is really no better way to bid adieu than with this grand and glorious final chapter.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "Poisson:\n",
      "positive\n",
      "Gaussian:\n",
      "positive\n",
      "Multinominal:\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "# print('Estimating text class for text: ', sampletext)\n",
    "print('Result: \\nPoisson:')\n",
    "text_estimate(sampletext, pnb, cv)\n",
    "print('Gaussian:')\n",
    "text_estimate(sampletext, gnb, cv)\n",
    "print('Multinominal:')\n",
    "text_estimate(sampletext, mnb, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__#8__ Сделайте выводы, почему наивный байесовский классификатор плохо или хорошо работает для данной задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Наивный байесовский классификатор хорошо подходит для широкого круга задач по анализу и классификации данных, и для данной задачи в частности. Это, в первую очередь, связанно с легкостью и высокой скоростью обучения данного классификатора ввиду большого упрощения задачи в принятии независимости всех признаков по совокупности  без существенной потери в эффективности предсказания (одно из основных преимуществ данного классификатора). Во вторых, использование данного классификатора рационально для данной задачи в виду необходимости малого числа данных для его обучения, а реализуемая задача как раз располагает ограниченным количеством данных в 2000 отзывов. К минусам же можно отнести тот факт, что в случае встречи неизвестного слова будет получена 0 вероятность и классификация будет затруднена без дополнительных изменений алгоритма.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
